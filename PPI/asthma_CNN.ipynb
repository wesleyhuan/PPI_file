{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8 定義所有需要的含式\n",
    "import io\n",
    "from numbers import Number\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "class EmptyFileError(Exception):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def __str__(self):\n",
    "        return repr(self.value)\n",
    "\n",
    "\n",
    "class FileNotSupportedError(Exception):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def __str__(self):\n",
    "        return repr(self.value)\n",
    "\n",
    "\n",
    "def open_rri(pathname_or_fileobj):\n",
    "    if isinstance(pathname_or_fileobj, str):\n",
    "        rri = _open_rri_from_path(pathname_or_fileobj)\n",
    "    elif isinstance(pathname_or_fileobj, io.TextIOWrapper):\n",
    "        rri = _open_rri_from_fileobj(pathname_or_fileobj)\n",
    "    return _transform_rri(rri)\n",
    "\n",
    "\n",
    "def _open_rri_from_path(pathname):\n",
    "    if pathname.endswith('.txt'):\n",
    "        with open(pathname, 'r') as fileobj:\n",
    "            rri = _open_rri_from_fileobj(fileobj)\n",
    "    elif pathname.endswith('.hrm'):\n",
    "        with open(pathname, 'r') as fileobj:\n",
    "            rri = _open_rri_from_fileobj(fileobj)\n",
    "    else:\n",
    "        raise FileNotSupportedError(\"File extension not supported\")\n",
    "    return rri\n",
    "\n",
    "\n",
    "def _open_rri_from_fileobj(fileobj):\n",
    "    file_content = fileobj.read()\n",
    "    file_type = _identify_rri_file_type(file_content)\n",
    "    if file_type == 'text':\n",
    "        rri = _open_rri_from_text(file_content)\n",
    "        if not rri:\n",
    "            raise EmptyFileError('File without rri data')\n",
    "    else:\n",
    "        rri = _open_rri_from_hrm(file_content)\n",
    "        if not rri:\n",
    "            raise EmptyFileError('File without rri data')\n",
    "    return rri\n",
    "\n",
    "\n",
    "def _open_rri_from_text(file_content):##----------------------------------------\n",
    "    rri = list(map(float,\n",
    "                   re.findall(r'\\S+' , file_content)))\n",
    "    return rri\n",
    "\n",
    "\n",
    "def _open_rri_from_hrm(file_content):\n",
    "    rri_info_index = file_content.find('[HRData]')\n",
    "    rri = None\n",
    "    if rri_info_index >= 0:\n",
    "        rri = list(map(float,\n",
    "                       re.findall(r'\\d+', file_content[rri_info_index:-1])))\n",
    "    return rri\n",
    "\n",
    "\n",
    "def _identify_rri_file_type(file_content):\n",
    "    is_hrm_file = file_content.find('[HRData]')\n",
    "    if is_hrm_file >= 0:\n",
    "        file_type = 'hrm'\n",
    "    else:\n",
    "        rri_lines = file_content.split('\\n')\n",
    "        for line in rri_lines:\n",
    "            current_line_number = re.findall(r'\\d+', line)\n",
    "            if current_line_number:\n",
    "                if  current_line_number[0] == line.strip():\n",
    "                    raise FileNotSupportedError('Text file not supported')\n",
    "        file_type = 'text'\n",
    "    return file_type\n",
    "\n",
    "\n",
    "def validate_rri(func):\n",
    "    def _validate(rri, *args, **kwargs):\n",
    "        _validate_positive_numbers(rri)\n",
    "        rri = _transform_rri(rri)\n",
    "        return func(rri, *args, **kwargs)\n",
    "\n",
    "    def _validate_positive_numbers(rri):\n",
    "        if not all(map(lambda value: isinstance(value, Number) and value > 0,\n",
    "                       rri)):\n",
    "            raise ValueError('rri must be a list or numpy.ndarray of positive'\n",
    "                             ' and non-zero numbers')\n",
    "\n",
    "    return _validate\n",
    "\n",
    "\n",
    "def _transform_rri(rri):\n",
    "    rri = _transform_rri_to_miliseconds(rri)\n",
    "    return np.array(rri)\n",
    "\n",
    "\n",
    "def validate_frequency_domain_arguments(func):\n",
    "    def _check_frequency_domain_arguments(rri, fs=4.0, method='welch',\n",
    "                                          interp_method='cubic', **kwargs):\n",
    "        _validate_available_methods(method)\n",
    "        return func(rri, fs, method, interp_method, **kwargs)\n",
    "\n",
    "    def _validate_available_methods(method):\n",
    "        available_methods = ('welch', 'ar')\n",
    "        if method not in available_methods:\n",
    "            raise ValueError('Method not supported! Choose among: {}'.format(\n",
    "                ', '.join(available_methods)))\n",
    "\n",
    "    return _check_frequency_domain_arguments\n",
    "\n",
    "\n",
    "def _create_time_info(rri):\n",
    "    rri_time = np.cumsum(rri) / 1000.0  # make it seconds\n",
    "    return rri_time - rri_time[0]   # force it to start at zero\n",
    "\n",
    "\n",
    "def _transform_rri_to_miliseconds(rri):\n",
    "    if np.median(rri) < 1:\n",
    "        rri *= 1000\n",
    "    return rri\n",
    "\n",
    "\n",
    "def _interpolate_rri(rri, fs=4, interp_method='cubic'):\n",
    "    if interp_method == 'cubic':\n",
    "        return _interp_cubic_spline(rri, fs)\n",
    "    elif interp_method == 'linear':\n",
    "        return _interp_linear(rri, fs)\n",
    "\n",
    "\n",
    "def _interp_cubic_spline(rri, fs):\n",
    "    time_rri = _create_time_info(rri)\n",
    "    time_rri_interp = _create_interp_time(rri, fs)\n",
    "    tck = interpolate.splrep(time_rri, rri, s=0)\n",
    "    rri_interp = interpolate.splev(time_rri_interp, tck, der=0)\n",
    "    return time_rri_interp, rri_interp\n",
    "\n",
    "\n",
    "def _interp_linear(rri, fs):\n",
    "    time_rri = _create_time_info(rri)\n",
    "    time_rri_interp = _create_interp_time(rri, fs)\n",
    "    rri_interp = np.interp(time_rri_interp, time_rri, rri)\n",
    "    return time_rri_interp, rri_interp\n",
    "\n",
    "\n",
    "def _create_interp_time(rri, fs):\n",
    "    time_rri = _create_time_info(rri)\n",
    "    return np.arange(0, time_rri[-1], 1 / float(fs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 自動增長 GPU 記憶體用量\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "# 設定 Keras 使用的 Session\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#引入基本資料庫\n",
    "from keras.datasets import mnist  \n",
    "from keras.utils import np_utils  \n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#2維矩陣的建立\\nHRVdata = []\\n\\nwith open(r'D:\\\\HRV_9_25\\x07ll_x_1.txt','r') as f:\\n    a = f.readline()\\na = a.split('  ')\\n#print(a)\\nfor char1 in a:\\n    HRVdata.append(float(char1))\\n#print(HRVdata)\\n\\nHRVdata=np.array(HRVdata)\\nHRVdata = HRVdata.reshape(9,25); \\n#print(HRVdata)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定義出normalize的函式\n",
    "import numpy as np\n",
    "class MapMinMaxApplier(object):\n",
    "    def __init__(self, slope, intercept):\n",
    "        self.slope = slope\n",
    "        self.intercept = intercept\n",
    "    def __call__(self, x):\n",
    "        return x * self.slope + self.intercept\n",
    "    def reverse(self, y):\n",
    "        return (y-self.intercept) / self.slope\n",
    " \n",
    "def mapminmax(x, ymin=-1, ymax=+1):\n",
    "\tx = np.asanyarray(x)\n",
    "\txmax = x.max(axis=-1)\n",
    "\txmin = x.min(axis=-1)\n",
    "\tif (xmax==xmin).any():\n",
    "\t\traise ValueError(\"some rows have no variation\")\n",
    "\tslope = ((ymax-ymin) / (xmax - xmin))[:,np.newaxis]\n",
    "\tintercept = (-xmin*(ymax-ymin)/(xmax-xmin))[:,np.newaxis] + ymin\n",
    "\tps = MapMinMaxApplier(slope, intercept)\n",
    "\treturn ps(x), ps\n",
    "\n",
    "'''#2維矩陣練習\n",
    "a = [[1, 2 ,3 ],[ 56 ,78 ,9]]\n",
    "#a = np.array(a)\n",
    "a[1][2]'''\n",
    "\n",
    "'''#2維矩陣的建立\n",
    "HRVdata = []\n",
    "\n",
    "with open(r'D:\\HRV_9_25\\all_x_1.txt','r') as f:\n",
    "    a = f.readline()\n",
    "a = a.split('  ')\n",
    "#print(a)\n",
    "for char1 in a:\n",
    "    HRVdata.append(float(char1))\n",
    "#print(HRVdata)\n",
    "\n",
    "HRVdata=np.array(HRVdata)\n",
    "HRVdata = HRVdata.reshape(9,25); \n",
    "#print(HRVdata)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#STEP1. 資料讀取與轉換 python3  \n",
    "from os import walk\n",
    "from os.path import join\n",
    "\n",
    "# 指定要列出所有檔案的目錄\n",
    "mypath = \"D:\\HRV_9_25\"\n",
    "#將資料歸零\n",
    "HRVdata=[]\n",
    "\n",
    "# 遞迴列出所有檔案的絕對路徑\n",
    "for root, dirs, files in walk(mypath):\n",
    "  for f in files:\n",
    "    fullpath = join(root, f)\n",
    "    #print(fullpath)\n",
    "    \n",
    "    test=[]\n",
    "    with open(fullpath,'r') as f:\n",
    "        test = f.readline()\n",
    "    test = test.split('  ')\n",
    "    #print(a)\n",
    "    #HRVdata=[]\n",
    "    for char1 in test:\n",
    "        HRVdata.append(float(char1))\n",
    "        \n",
    "HRVdata = np.array(HRVdata)\n",
    "\n",
    "HRVdata = HRVdata.reshape(172,225)\n",
    "\n",
    "#print(HRVdata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#進行輸入矩陣的normalize\n",
    "HRVdata,ps1=mapminmax(HRVdata,-1,1); #默认为-1,1\n",
    "HRVdata = HRVdata.reshape(172,9,25,1)\n",
    "#print(HRVdata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0有asthma、1沒有asthma\n",
    "label = []\n",
    "\n",
    "with open(r'D:\\all_y.txt','r') as f:\n",
    "    a = f.readline()\n",
    "a = a.split('  ')\n",
    "#print(a)\n",
    "for char1 in a:\n",
    "    label.append(float(char1)-1)\n",
    "    \n",
    "#print(label)\n",
    "\n",
    "# Label 的 Onehot encoding \n",
    "labelOneHot = np_utils.to_categorical(label)  \n",
    "\n",
    "#print(labelOneHot[1])\n",
    "#print(labelOneHot[1].size)\n",
    "#以上完成輸入X及Y的基本設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP1. 建立卷積層與池化層 \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D  \n",
    "  \n",
    "model = Sequential()  \n",
    "# Create CN layer 1  \n",
    "model.add(Conv2D(filters=52,\n",
    "                 kernel_size=(1,9),\n",
    "                 padding='same',  \n",
    "                 input_shape=(9,25,1),  \n",
    "                 activation='relu'))  \n",
    "# Create Max-Pool 1  \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))   \n",
    "'''# Create CN layer 2 \n",
    "model.add(Conv2D(filters=26,\n",
    "                 kernel_size=(1,9),\n",
    "                 padding='same',  \n",
    "                 input_shape=(9,25,1),  \n",
    "                 activation='relu'))  \n",
    "# Create Max-Pool 2  \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))   \n",
    "\n",
    "# Add Dropout layer  \n",
    "#model.add(Dropout(0.25))  '''\n",
    "\n",
    "#STEP2. 建立神經網路 \n",
    "#建立平坦層 \n",
    "#下面程式碼建立平坦層, 將之前步驟已經建立的池化層2\n",
    "model.add(Flatten()) \n",
    "\n",
    "#建立 Hidden layer \n",
    "model.add(Dense(255, activation='relu'))  \n",
    "model.add(Dropout(0.25)) \n",
    "\n",
    "#建立輸出層 \n",
    "#最後建立輸出層, 共有 2 個神經元, 對應到 0~1 共兩個結果. 並使用 softmax 激活函數 進行轉換 (softmax 函數可以將神經元的輸出轉換成每一個數字的機率):\n",
    "model.add(Dense(2, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 9, 25, 52)         520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 12, 52)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 255)               636735    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 255)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 512       \n",
      "=================================================================\n",
      "Total params: 637,767\n",
      "Trainable params: 637,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#STEP3. 查看模型的摘要\n",
    "model.summary()  \n",
    "print(\"\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 115 samples, validate on 57 samples\n",
      "Epoch 1/1000\n",
      "115/115 [==============================] - 2s 17ms/step - loss: 0.6522 - acc: 0.7304 - val_loss: 1.1790 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.5868 - acc: 0.7478 - val_loss: 1.6602 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.5820 - acc: 0.7478 - val_loss: 1.1922 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5445 - acc: 0.7478 - val_loss: 1.6813 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5560 - acc: 0.7478 - val_loss: 1.2765 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5677 - acc: 0.7478 - val_loss: 1.3905 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5376 - acc: 0.7478 - val_loss: 2.1989 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5918 - acc: 0.7478 - val_loss: 1.5621 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5685 - acc: 0.7478 - val_loss: 1.3741 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5772 - acc: 0.7478 - val_loss: 0.9849 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5626 - acc: 0.7478 - val_loss: 1.3103 - val_acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5431 - acc: 0.7478 - val_loss: 1.6640 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5517 - acc: 0.7478 - val_loss: 1.2950 - val_acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.5399 - acc: 0.7478 - val_loss: 1.6736 - val_acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5321 - acc: 0.7478 - val_loss: 1.4234 - val_acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5241 - acc: 0.7565 - val_loss: 1.7904 - val_acc: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5446 - acc: 0.7565 - val_loss: 1.2931 - val_acc: 0.0175\n",
      "Epoch 18/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5128 - acc: 0.7478 - val_loss: 1.6098 - val_acc: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5080 - acc: 0.7565 - val_loss: 1.3154 - val_acc: 0.0175\n",
      "Epoch 20/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5312 - acc: 0.7652 - val_loss: 1.6537 - val_acc: 0.0175\n",
      "Epoch 21/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5164 - acc: 0.7652 - val_loss: 1.4992 - val_acc: 0.0175\n",
      "Epoch 22/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5103 - acc: 0.7652 - val_loss: 1.6650 - val_acc: 0.0175\n",
      "Epoch 23/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5084 - acc: 0.7565 - val_loss: 1.9164 - val_acc: 0.0175\n",
      "Epoch 24/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5041 - acc: 0.7652 - val_loss: 1.9371 - val_acc: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.5033 - acc: 0.7652 - val_loss: 1.4783 - val_acc: 0.0351\n",
      "Epoch 26/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4872 - acc: 0.7652 - val_loss: 1.8167 - val_acc: 0.0351\n",
      "Epoch 27/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4943 - acc: 0.7739 - val_loss: 1.9246 - val_acc: 0.0351\n",
      "Epoch 28/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4810 - acc: 0.7739 - val_loss: 2.5255 - val_acc: 0.0175\n",
      "Epoch 29/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4731 - acc: 0.7739 - val_loss: 1.4003 - val_acc: 0.0526\n",
      "Epoch 30/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4884 - acc: 0.7565 - val_loss: 1.9336 - val_acc: 0.0351\n",
      "Epoch 31/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4829 - acc: 0.7652 - val_loss: 1.5305 - val_acc: 0.0526\n",
      "Epoch 32/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4641 - acc: 0.7826 - val_loss: 1.6499 - val_acc: 0.0351\n",
      "Epoch 33/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4607 - acc: 0.8000 - val_loss: 2.1842 - val_acc: 0.0351\n",
      "Epoch 34/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4619 - acc: 0.7826 - val_loss: 2.2500 - val_acc: 0.0351\n",
      "Epoch 35/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4634 - acc: 0.7739 - val_loss: 2.0340 - val_acc: 0.0351\n",
      "Epoch 36/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4351 - acc: 0.7739 - val_loss: 2.0123 - val_acc: 0.0351\n",
      "Epoch 37/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.4472 - acc: 0.7826 - val_loss: 2.1066 - val_acc: 0.0526\n",
      "Epoch 38/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4406 - acc: 0.7739 - val_loss: 2.3478 - val_acc: 0.0702\n",
      "Epoch 39/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4189 - acc: 0.8000 - val_loss: 3.1735 - val_acc: 0.0351\n",
      "Epoch 40/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.4087 - acc: 0.7826 - val_loss: 5.2697 - val_acc: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4585 - acc: 0.8174 - val_loss: 2.2812 - val_acc: 0.0702\n",
      "Epoch 42/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3895 - acc: 0.8087 - val_loss: 3.1237 - val_acc: 0.0526\n",
      "Epoch 43/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4360 - acc: 0.7739 - val_loss: 3.0979 - val_acc: 0.0351\n",
      "Epoch 44/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4306 - acc: 0.7913 - val_loss: 2.4891 - val_acc: 0.0877\n",
      "Epoch 45/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4044 - acc: 0.8087 - val_loss: 3.4898 - val_acc: 0.0351\n",
      "Epoch 46/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4173 - acc: 0.8087 - val_loss: 2.5775 - val_acc: 0.0526\n",
      "Epoch 47/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4040 - acc: 0.7913 - val_loss: 2.7368 - val_acc: 0.0526\n",
      "Epoch 48/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.3839 - acc: 0.8348 - val_loss: 2.3846 - val_acc: 0.0877\n",
      "Epoch 49/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3894 - acc: 0.8261 - val_loss: 3.2548 - val_acc: 0.0526\n",
      "Epoch 50/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3806 - acc: 0.8261 - val_loss: 2.6264 - val_acc: 0.2105\n",
      "Epoch 51/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4042 - acc: 0.8174 - val_loss: 2.9144 - val_acc: 0.0702\n",
      "Epoch 52/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3685 - acc: 0.8087 - val_loss: 3.1295 - val_acc: 0.1404\n",
      "Epoch 53/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4043 - acc: 0.7826 - val_loss: 2.9195 - val_acc: 0.0877\n",
      "Epoch 54/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3737 - acc: 0.7913 - val_loss: 3.2078 - val_acc: 0.2456\n",
      "Epoch 55/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3734 - acc: 0.8174 - val_loss: 3.0970 - val_acc: 0.1053\n",
      "Epoch 56/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3453 - acc: 0.8174 - val_loss: 3.9688 - val_acc: 0.0702\n",
      "Epoch 57/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3725 - acc: 0.8087 - val_loss: 2.7352 - val_acc: 0.5263\n",
      "Epoch 58/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3674 - acc: 0.8174 - val_loss: 3.7941 - val_acc: 0.0702\n",
      "Epoch 59/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.3548 - acc: 0.8522 - val_loss: 3.6783 - val_acc: 0.1053\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 13ms/step - loss: 0.3752 - acc: 0.8087 - val_loss: 3.0530 - val_acc: 0.1053\n",
      "Epoch 61/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3578 - acc: 0.8435 - val_loss: 3.6081 - val_acc: 0.0526\n",
      "Epoch 62/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3485 - acc: 0.8348 - val_loss: 4.0211 - val_acc: 0.1228\n",
      "Epoch 63/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3530 - acc: 0.8348 - val_loss: 3.9049 - val_acc: 0.0526\n",
      "Epoch 64/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3538 - acc: 0.8261 - val_loss: 3.1939 - val_acc: 0.2105\n",
      "Epoch 65/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3722 - acc: 0.8261 - val_loss: 3.8527 - val_acc: 0.1228\n",
      "Epoch 66/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3489 - acc: 0.8261 - val_loss: 3.8381 - val_acc: 0.1053\n",
      "Epoch 67/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3366 - acc: 0.8348 - val_loss: 4.6652 - val_acc: 0.0702\n",
      "Epoch 68/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3362 - acc: 0.8000 - val_loss: 3.8543 - val_acc: 0.1053\n",
      "Epoch 69/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3585 - acc: 0.8087 - val_loss: 3.3127 - val_acc: 0.1754\n",
      "Epoch 70/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3332 - acc: 0.8174 - val_loss: 3.8784 - val_acc: 0.1404\n",
      "Epoch 71/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.3479 - acc: 0.8174 - val_loss: 4.1017 - val_acc: 0.1228\n",
      "Epoch 72/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.3230 - acc: 0.8261 - val_loss: 3.9069 - val_acc: 0.1754\n",
      "Epoch 73/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.3388 - acc: 0.8174 - val_loss: 3.6731 - val_acc: 0.3158\n",
      "Epoch 74/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3238 - acc: 0.8609 - val_loss: 3.9143 - val_acc: 0.2105\n",
      "Epoch 75/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3095 - acc: 0.8609 - val_loss: 5.2147 - val_acc: 0.0351\n",
      "Epoch 76/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3167 - acc: 0.8348 - val_loss: 3.7866 - val_acc: 0.1754\n",
      "Epoch 77/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3121 - acc: 0.8696 - val_loss: 4.1976 - val_acc: 0.1404\n",
      "Epoch 78/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2947 - acc: 0.8435 - val_loss: 3.9519 - val_acc: 0.1404\n",
      "Epoch 79/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3721 - acc: 0.8261 - val_loss: 3.2881 - val_acc: 0.3509\n",
      "Epoch 80/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3094 - acc: 0.8783 - val_loss: 4.4980 - val_acc: 0.1053\n",
      "Epoch 81/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2990 - acc: 0.8609 - val_loss: 4.0491 - val_acc: 0.1754\n",
      "Epoch 82/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.3203 - acc: 0.8261 - val_loss: 4.4937 - val_acc: 0.1404\n",
      "Epoch 83/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.3302 - acc: 0.8435 - val_loss: 3.9155 - val_acc: 0.1579\n",
      "Epoch 84/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2999 - acc: 0.8522 - val_loss: 3.9870 - val_acc: 0.2807\n",
      "Epoch 85/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2992 - acc: 0.8522 - val_loss: 3.7447 - val_acc: 0.3684\n",
      "Epoch 86/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2986 - acc: 0.8435 - val_loss: 3.9385 - val_acc: 0.2807\n",
      "Epoch 87/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3097 - acc: 0.8522 - val_loss: 3.9785 - val_acc: 0.3509\n",
      "Epoch 88/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2788 - acc: 0.8696 - val_loss: 5.2497 - val_acc: 0.1053\n",
      "Epoch 89/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3240 - acc: 0.8348 - val_loss: 4.8517 - val_acc: 0.1053\n",
      "Epoch 90/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3053 - acc: 0.8348 - val_loss: 3.7796 - val_acc: 0.3684\n",
      "Epoch 91/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3039 - acc: 0.8522 - val_loss: 4.5350 - val_acc: 0.1579\n",
      "Epoch 92/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2840 - acc: 0.8522 - val_loss: 5.4521 - val_acc: 0.1053\n",
      "Epoch 93/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.3066 - acc: 0.8435 - val_loss: 4.1510 - val_acc: 0.2281\n",
      "Epoch 94/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.2891 - acc: 0.8609 - val_loss: 4.3078 - val_acc: 0.1754\n",
      "Epoch 95/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2952 - acc: 0.8435 - val_loss: 4.9139 - val_acc: 0.1579\n",
      "Epoch 96/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2926 - acc: 0.8696 - val_loss: 4.5147 - val_acc: 0.1404\n",
      "Epoch 97/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2861 - acc: 0.8522 - val_loss: 4.9591 - val_acc: 0.1053\n",
      "Epoch 98/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2782 - acc: 0.8522 - val_loss: 4.7831 - val_acc: 0.2105\n",
      "Epoch 99/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.2801 - acc: 0.873 - 1s 12ms/step - loss: 0.2793 - acc: 0.8783 - val_loss: 4.4209 - val_acc: 0.1930\n",
      "Epoch 100/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2966 - acc: 0.8522 - val_loss: 4.4064 - val_acc: 0.2982\n",
      "Epoch 101/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2760 - acc: 0.8783 - val_loss: 4.1438 - val_acc: 0.2281\n",
      "Epoch 102/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2660 - acc: 0.8870 - val_loss: 5.2245 - val_acc: 0.1228\n",
      "Epoch 103/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2892 - acc: 0.8261 - val_loss: 4.9414 - val_acc: 0.1404\n",
      "Epoch 104/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2779 - acc: 0.8957 - val_loss: 4.4237 - val_acc: 0.2281\n",
      "Epoch 105/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2791 - acc: 0.8609 - val_loss: 4.1694 - val_acc: 0.2632\n",
      "Epoch 106/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.2478 - acc: 0.8783 - val_loss: 4.6847 - val_acc: 0.1754\n",
      "Epoch 107/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2747 - acc: 0.8348 - val_loss: 5.1768 - val_acc: 0.1404\n",
      "Epoch 108/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2716 - acc: 0.8348 - val_loss: 4.6237 - val_acc: 0.1404\n",
      "Epoch 109/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2985 - acc: 0.8435 - val_loss: 4.6975 - val_acc: 0.1404\n",
      "Epoch 110/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2456 - acc: 0.8609 - val_loss: 4.5855 - val_acc: 0.4035\n",
      "Epoch 111/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2793 - acc: 0.8609 - val_loss: 4.4464 - val_acc: 0.2281\n",
      "Epoch 112/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2388 - acc: 0.8783 - val_loss: 4.9026 - val_acc: 0.1404\n",
      "Epoch 113/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2977 - acc: 0.8609 - val_loss: 4.3945 - val_acc: 0.1930\n",
      "Epoch 114/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2486 - acc: 0.8870 - val_loss: 5.5068 - val_acc: 0.0526\n",
      "Epoch 115/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2574 - acc: 0.8696 - val_loss: 4.5313 - val_acc: 0.2807\n",
      "Epoch 116/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2557 - acc: 0.8609 - val_loss: 4.4310 - val_acc: 0.2632\n",
      "Epoch 117/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.2679 - acc: 0.8609 - val_loss: 4.4531 - val_acc: 0.2281\n",
      "Epoch 118/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.2696 - acc: 0.8609 - val_loss: 4.7356 - val_acc: 0.1930\n",
      "Epoch 119/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2547 - acc: 0.8783 - val_loss: 5.2976 - val_acc: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2668 - acc: 0.8522 - val_loss: 4.7722 - val_acc: 0.2105\n",
      "Epoch 121/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2710 - acc: 0.8783 - val_loss: 4.7779 - val_acc: 0.1579\n",
      "Epoch 122/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2284 - acc: 0.9130 - val_loss: 5.9177 - val_acc: 0.0877\n",
      "Epoch 123/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2589 - acc: 0.8870 - val_loss: 5.2612 - val_acc: 0.1404\n",
      "Epoch 124/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2695 - acc: 0.8783 - val_loss: 5.3501 - val_acc: 0.1228\n",
      "Epoch 125/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2607 - acc: 0.8783 - val_loss: 5.9128 - val_acc: 0.0526\n",
      "Epoch 126/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2619 - acc: 0.8696 - val_loss: 5.2472 - val_acc: 0.0877\n",
      "Epoch 127/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2621 - acc: 0.8609 - val_loss: 5.8012 - val_acc: 0.0526\n",
      "Epoch 128/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2643 - acc: 0.8696 - val_loss: 4.9881 - val_acc: 0.1228\n",
      "Epoch 129/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.2404 - acc: 0.8696 - val_loss: 5.4554 - val_acc: 0.1053\n",
      "Epoch 130/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2550 - acc: 0.8609 - val_loss: 4.3629 - val_acc: 0.2632\n",
      "Epoch 131/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2552 - acc: 0.9043 - val_loss: 5.3723 - val_acc: 0.1404\n",
      "Epoch 132/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2386 - acc: 0.8870 - val_loss: 5.3670 - val_acc: 0.1404\n",
      "Epoch 133/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2438 - acc: 0.8957 - val_loss: 5.3235 - val_acc: 0.1228\n",
      "Epoch 134/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.5057 - acc: 0.8174 - val_loss: 3.8819 - val_acc: 0.2105\n",
      "Epoch 135/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2745 - acc: 0.8522 - val_loss: 5.3939 - val_acc: 0.0877\n",
      "Epoch 136/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2172 - acc: 0.8522 - val_loss: 5.2181 - val_acc: 0.1404\n",
      "Epoch 137/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2464 - acc: 0.8696 - val_loss: 4.6106 - val_acc: 0.1754\n",
      "Epoch 138/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2523 - acc: 0.8783 - val_loss: 5.1093 - val_acc: 0.1754\n",
      "Epoch 139/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2224 - acc: 0.8957 - val_loss: 5.6605 - val_acc: 0.1404\n",
      "Epoch 140/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.2165 - acc: 0.9217 - val_loss: 5.5137 - val_acc: 0.1579\n",
      "Epoch 141/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.2419 - acc: 0.8609 - val_loss: 5.4994 - val_acc: 0.1228\n",
      "Epoch 142/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2223 - acc: 0.8870 - val_loss: 6.0676 - val_acc: 0.0702\n",
      "Epoch 143/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1892 - acc: 0.9043 - val_loss: 4.7005 - val_acc: 0.3509\n",
      "Epoch 144/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2414 - acc: 0.9130 - val_loss: 5.2952 - val_acc: 0.1754\n",
      "Epoch 145/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2456 - acc: 0.8609 - val_loss: 5.5479 - val_acc: 0.1404\n",
      "Epoch 146/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2466 - acc: 0.8783 - val_loss: 5.3079 - val_acc: 0.0702\n",
      "Epoch 147/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2340 - acc: 0.8957 - val_loss: 5.4095 - val_acc: 0.1404\n",
      "Epoch 148/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2106 - acc: 0.8870 - val_loss: 5.2688 - val_acc: 0.1930\n",
      "Epoch 149/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2129 - acc: 0.9043 - val_loss: 5.2830 - val_acc: 0.1579\n",
      "Epoch 150/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2367 - acc: 0.9130 - val_loss: 5.9296 - val_acc: 0.0702\n",
      "Epoch 151/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2634 - acc: 0.8435 - val_loss: 4.9071 - val_acc: 0.2632\n",
      "Epoch 152/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.2153 - acc: 0.9130 - val_loss: 5.1119 - val_acc: 0.1930\n",
      "Epoch 153/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2140 - acc: 0.9217 - val_loss: 5.4455 - val_acc: 0.1579\n",
      "Epoch 154/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2404 - acc: 0.8870 - val_loss: 5.6034 - val_acc: 0.1579\n",
      "Epoch 155/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2048 - acc: 0.8870 - val_loss: 5.7159 - val_acc: 0.1228\n",
      "Epoch 156/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2058 - acc: 0.8957 - val_loss: 6.0414 - val_acc: 0.0877\n",
      "Epoch 157/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.2207 - acc: 0.9043 - val_loss: 5.3418 - val_acc: 0.1579\n",
      "Epoch 158/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2089 - acc: 0.8957 - val_loss: 5.0415 - val_acc: 0.2807\n",
      "Epoch 159/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2379 - acc: 0.9043 - val_loss: 6.0589 - val_acc: 0.1053\n",
      "Epoch 160/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2471 - acc: 0.8957 - val_loss: 4.4107 - val_acc: 0.2281\n",
      "Epoch 161/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2214 - acc: 0.8957 - val_loss: 5.1128 - val_acc: 0.1754\n",
      "Epoch 162/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2298 - acc: 0.8783 - val_loss: 5.6978 - val_acc: 0.1579\n",
      "Epoch 163/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1907 - acc: 0.9043 - val_loss: 4.8160 - val_acc: 0.3509\n",
      "Epoch 164/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1966 - acc: 0.9217 - val_loss: 5.4899 - val_acc: 0.1930\n",
      "Epoch 165/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.2157 - acc: 0.8957 - val_loss: 5.2226 - val_acc: 0.2281\n",
      "Epoch 166/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2638 - acc: 0.8870 - val_loss: 5.0760 - val_acc: 0.2456\n",
      "Epoch 167/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2052 - acc: 0.9043 - val_loss: 5.2996 - val_acc: 0.2632\n",
      "Epoch 168/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1811 - acc: 0.8957 - val_loss: 5.7637 - val_acc: 0.1404\n",
      "Epoch 169/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2067 - acc: 0.9130 - val_loss: 5.8697 - val_acc: 0.1228\n",
      "Epoch 170/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2036 - acc: 0.8783 - val_loss: 5.0286 - val_acc: 0.2456\n",
      "Epoch 171/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2052 - acc: 0.9043 - val_loss: 4.7105 - val_acc: 0.4386\n",
      "Epoch 172/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2111 - acc: 0.8957 - val_loss: 5.8663 - val_acc: 0.1754\n",
      "Epoch 173/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1799 - acc: 0.9391 - val_loss: 5.9518 - val_acc: 0.1228\n",
      "Epoch 174/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1842 - acc: 0.9043 - val_loss: 5.2451 - val_acc: 0.2632\n",
      "Epoch 175/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1896 - acc: 0.8783 - val_loss: 5.1707 - val_acc: 0.3158\n",
      "Epoch 176/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1928 - acc: 0.9130 - val_loss: 5.6709 - val_acc: 0.2105\n",
      "Epoch 177/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1868 - acc: 0.9217 - val_loss: 6.7808 - val_acc: 0.0702\n",
      "Epoch 178/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2025 - acc: 0.9217 - val_loss: 5.1353 - val_acc: 0.2456\n",
      "Epoch 179/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1897 - acc: 0.8870 - val_loss: 5.3153 - val_acc: 0.2105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1884 - acc: 0.9130 - val_loss: 5.7626 - val_acc: 0.1930\n",
      "Epoch 181/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1708 - acc: 0.9130 - val_loss: 6.4740 - val_acc: 0.0702\n",
      "Epoch 182/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1809 - acc: 0.9130 - val_loss: 6.4234 - val_acc: 0.0702\n",
      "Epoch 183/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1656 - acc: 0.9304 - val_loss: 5.6980 - val_acc: 0.2281\n",
      "Epoch 184/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1965 - acc: 0.9043 - val_loss: 5.9022 - val_acc: 0.1579\n",
      "Epoch 185/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1660 - acc: 0.9304 - val_loss: 6.7621 - val_acc: 0.0702\n",
      "Epoch 186/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1771 - acc: 0.8957 - val_loss: 6.4944 - val_acc: 0.0877\n",
      "Epoch 187/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1738 - acc: 0.9130 - val_loss: 7.7697 - val_acc: 0.0702\n",
      "Epoch 188/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2252 - acc: 0.8870 - val_loss: 6.0053 - val_acc: 0.2281\n",
      "Epoch 189/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1608 - acc: 0.9304 - val_loss: 6.5382 - val_acc: 0.1228\n",
      "Epoch 190/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1539 - acc: 0.9391 - val_loss: 5.7268 - val_acc: 0.2982\n",
      "Epoch 191/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1849 - acc: 0.9217 - val_loss: 6.5722 - val_acc: 0.1228\n",
      "Epoch 192/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2132 - acc: 0.9043 - val_loss: 6.5971 - val_acc: 0.1754\n",
      "Epoch 193/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1482 - acc: 0.9217 - val_loss: 6.5540 - val_acc: 0.1404\n",
      "Epoch 194/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1819 - acc: 0.8957 - val_loss: 6.0379 - val_acc: 0.1754\n",
      "Epoch 195/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1918 - acc: 0.9304 - val_loss: 5.5001 - val_acc: 0.3158\n",
      "Epoch 196/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1548 - acc: 0.9217 - val_loss: 6.3461 - val_acc: 0.1228\n",
      "Epoch 197/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1635 - acc: 0.9130 - val_loss: 6.7906 - val_acc: 0.1404\n",
      "Epoch 198/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1578 - acc: 0.9217 - val_loss: 5.8322 - val_acc: 0.2632\n",
      "Epoch 199/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1783 - acc: 0.9217 - val_loss: 6.5748 - val_acc: 0.1930\n",
      "Epoch 200/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1755 - acc: 0.9130 - val_loss: 7.3782 - val_acc: 0.0702\n",
      "Epoch 201/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1698 - acc: 0.9391 - val_loss: 7.0047 - val_acc: 0.1404\n",
      "Epoch 202/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1498 - acc: 0.9478 - val_loss: 6.8074 - val_acc: 0.1579\n",
      "Epoch 203/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1604 - acc: 0.9217 - val_loss: 6.1672 - val_acc: 0.1754\n",
      "Epoch 204/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1726 - acc: 0.9130 - val_loss: 6.7750 - val_acc: 0.1053\n",
      "Epoch 205/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1663 - acc: 0.9130 - val_loss: 6.7664 - val_acc: 0.1228\n",
      "Epoch 206/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1942 - acc: 0.9043 - val_loss: 5.9064 - val_acc: 0.3158\n",
      "Epoch 207/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2161 - acc: 0.9043 - val_loss: 6.3206 - val_acc: 0.1404\n",
      "Epoch 208/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1554 - acc: 0.9217 - val_loss: 6.0253 - val_acc: 0.2456\n",
      "Epoch 209/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1493 - acc: 0.9391 - val_loss: 6.0466 - val_acc: 0.2807\n",
      "Epoch 210/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1454 - acc: 0.9565 - val_loss: 5.9257 - val_acc: 0.2632\n",
      "Epoch 211/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1350 - acc: 0.9391 - val_loss: 7.0019 - val_acc: 0.1228\n",
      "Epoch 212/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1430 - acc: 0.9565 - val_loss: 6.7537 - val_acc: 0.1404\n",
      "Epoch 213/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1124 - acc: 0.9478 - val_loss: 7.3029 - val_acc: 0.0877\n",
      "Epoch 214/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1680 - acc: 0.9043 - val_loss: 7.1412 - val_acc: 0.1053\n",
      "Epoch 215/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1711 - acc: 0.9217 - val_loss: 6.0158 - val_acc: 0.2632\n",
      "Epoch 216/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1480 - acc: 0.9391 - val_loss: 7.0503 - val_acc: 0.1579\n",
      "Epoch 217/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1246 - acc: 0.9478 - val_loss: 7.0608 - val_acc: 0.1053\n",
      "Epoch 218/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1829 - acc: 0.9217 - val_loss: 6.2991 - val_acc: 0.2105\n",
      "Epoch 219/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1137 - acc: 0.9739 - val_loss: 6.4512 - val_acc: 0.2105\n",
      "Epoch 220/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1547 - acc: 0.8957 - val_loss: 6.0545 - val_acc: 0.3333\n",
      "Epoch 221/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1568 - acc: 0.9130 - val_loss: 6.4886 - val_acc: 0.2105\n",
      "Epoch 222/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1279 - acc: 0.9391 - val_loss: 6.6578 - val_acc: 0.1754\n",
      "Epoch 223/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1509 - acc: 0.9130 - val_loss: 6.2763 - val_acc: 0.2982\n",
      "Epoch 224/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1147 - acc: 0.9565 - val_loss: 7.8221 - val_acc: 0.0702\n",
      "Epoch 225/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1745 - acc: 0.8957 - val_loss: 7.3373 - val_acc: 0.0702\n",
      "Epoch 226/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1134 - acc: 0.9652 - val_loss: 7.1519 - val_acc: 0.1228\n",
      "Epoch 227/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1131 - acc: 0.9391 - val_loss: 7.4057 - val_acc: 0.0877\n",
      "Epoch 228/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2149 - acc: 0.9043 - val_loss: 6.1180 - val_acc: 0.1053\n",
      "Epoch 229/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1464 - acc: 0.9565 - val_loss: 6.0825 - val_acc: 0.3509\n",
      "Epoch 230/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1197 - acc: 0.9565 - val_loss: 7.0519 - val_acc: 0.1579\n",
      "Epoch 231/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1108 - acc: 0.9391 - val_loss: 6.2695 - val_acc: 0.3158\n",
      "Epoch 232/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1368 - acc: 0.9217 - val_loss: 6.4726 - val_acc: 0.2456\n",
      "Epoch 233/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.1193 - acc: 0.9391 - val_loss: 6.6279 - val_acc: 0.2105\n",
      "Epoch 234/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1192 - acc: 0.9565 - val_loss: 6.7039 - val_acc: 0.1930\n",
      "Epoch 235/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1307 - acc: 0.9478 - val_loss: 7.0430 - val_acc: 0.1404\n",
      "Epoch 236/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1321 - acc: 0.9478 - val_loss: 7.0245 - val_acc: 0.1228\n",
      "Epoch 237/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1210 - acc: 0.9391 - val_loss: 6.7108 - val_acc: 0.1930\n",
      "Epoch 238/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1416 - acc: 0.9304 - val_loss: 6.5901 - val_acc: 0.1930\n",
      "Epoch 239/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1289 - acc: 0.9391 - val_loss: 6.2440 - val_acc: 0.2982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1201 - acc: 0.9391 - val_loss: 7.2829 - val_acc: 0.1228\n",
      "Epoch 241/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1065 - acc: 0.9565 - val_loss: 6.6222 - val_acc: 0.1930\n",
      "Epoch 242/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1241 - acc: 0.9478 - val_loss: 6.0710 - val_acc: 0.3684\n",
      "Epoch 243/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1089 - acc: 0.9652 - val_loss: 7.0061 - val_acc: 0.1930\n",
      "Epoch 244/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1147 - acc: 0.9478 - val_loss: 6.2541 - val_acc: 0.3509\n",
      "Epoch 245/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1152 - acc: 0.9565 - val_loss: 6.7740 - val_acc: 0.2456\n",
      "Epoch 246/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0990 - acc: 0.9565 - val_loss: 7.2982 - val_acc: 0.1579\n",
      "Epoch 247/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1272 - acc: 0.9391 - val_loss: 7.1811 - val_acc: 0.1754\n",
      "Epoch 248/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0898 - acc: 0.9565 - val_loss: 6.8668 - val_acc: 0.2105\n",
      "Epoch 249/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.0854 - acc: 0.9826 - val_loss: 7.0299 - val_acc: 0.2281\n",
      "Epoch 250/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0981 - acc: 0.9565 - val_loss: 6.9015 - val_acc: 0.2807\n",
      "Epoch 251/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0969 - acc: 0.9652 - val_loss: 6.8752 - val_acc: 0.2632\n",
      "Epoch 252/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0994 - acc: 0.9565 - val_loss: 6.5517 - val_acc: 0.3333\n",
      "Epoch 253/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0838 - acc: 0.9652 - val_loss: 6.6264 - val_acc: 0.2982\n",
      "Epoch 254/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1058 - acc: 0.9565 - val_loss: 7.6215 - val_acc: 0.1404\n",
      "Epoch 255/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1301 - acc: 0.9217 - val_loss: 7.6345 - val_acc: 0.1579\n",
      "Epoch 256/1000\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 0.1427 - acc: 0.9478 - val_loss: 6.9652 - val_acc: 0.1579\n",
      "Epoch 257/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2071 - acc: 0.9217 - val_loss: 6.8476 - val_acc: 0.2105\n",
      "Epoch 258/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1016 - acc: 0.9652 - val_loss: 7.4241 - val_acc: 0.1404\n",
      "Epoch 259/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1183 - acc: 0.9304 - val_loss: 7.1888 - val_acc: 0.1404\n",
      "Epoch 260/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1058 - acc: 0.9652 - val_loss: 6.9653 - val_acc: 0.2105\n",
      "Epoch 261/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0974 - acc: 0.9565 - val_loss: 7.1207 - val_acc: 0.1930\n",
      "Epoch 262/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1056 - acc: 0.9652 - val_loss: 6.9754 - val_acc: 0.1930\n",
      "Epoch 263/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0980 - acc: 0.9739 - val_loss: 7.0813 - val_acc: 0.2281\n",
      "Epoch 264/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0806 - acc: 0.9739 - val_loss: 7.5272 - val_acc: 0.1228\n",
      "Epoch 265/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0976 - acc: 0.9652 - val_loss: 6.9342 - val_acc: 0.2632\n",
      "Epoch 266/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1310 - acc: 0.9217 - val_loss: 7.7991 - val_acc: 0.1754\n",
      "Epoch 267/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1282 - acc: 0.9478 - val_loss: 7.4290 - val_acc: 0.1053\n",
      "Epoch 268/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1136 - acc: 0.9565 - val_loss: 6.9583 - val_acc: 0.2632\n",
      "Epoch 269/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0905 - acc: 0.9739 - val_loss: 7.2257 - val_acc: 0.1754\n",
      "Epoch 270/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0837 - acc: 0.9652 - val_loss: 7.8144 - val_acc: 0.0702\n",
      "Epoch 271/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1221 - acc: 0.9391 - val_loss: 7.2261 - val_acc: 0.1579\n",
      "Epoch 272/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0870 - acc: 0.9565 - val_loss: 6.9317 - val_acc: 0.2632\n",
      "Epoch 273/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0792 - acc: 0.9652 - val_loss: 7.3106 - val_acc: 0.1754\n",
      "Epoch 274/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0938 - acc: 0.9739 - val_loss: 7.0752 - val_acc: 0.1404\n",
      "Epoch 275/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1718 - acc: 0.9217 - val_loss: 6.6667 - val_acc: 0.2281\n",
      "Epoch 276/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1143 - acc: 0.9478 - val_loss: 7.4362 - val_acc: 0.1579\n",
      "Epoch 277/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0947 - acc: 0.9739 - val_loss: 6.6357 - val_acc: 0.2281\n",
      "Epoch 278/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0877 - acc: 0.9652 - val_loss: 6.5606 - val_acc: 0.2982\n",
      "Epoch 279/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0866 - acc: 0.9565 - val_loss: 7.0702 - val_acc: 0.1579\n",
      "Epoch 280/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1270 - acc: 0.9478 - val_loss: 8.0421 - val_acc: 0.1053\n",
      "Epoch 281/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0841 - acc: 0.9826 - val_loss: 7.0446 - val_acc: 0.1754\n",
      "Epoch 282/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0826 - acc: 0.9652 - val_loss: 6.7026 - val_acc: 0.3158\n",
      "Epoch 283/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0882 - acc: 0.9739 - val_loss: 7.2639 - val_acc: 0.1754\n",
      "Epoch 284/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0916 - acc: 0.9652 - val_loss: 7.0874 - val_acc: 0.2632\n",
      "Epoch 285/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0712 - acc: 0.9565 - val_loss: 6.8330 - val_acc: 0.2807\n",
      "Epoch 286/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0629 - acc: 0.9913 - val_loss: 7.9249 - val_acc: 0.1404\n",
      "Epoch 287/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0705 - acc: 0.9739 - val_loss: 6.9700 - val_acc: 0.2982\n",
      "Epoch 288/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0569 - acc: 0.9913 - val_loss: 7.1375 - val_acc: 0.2281\n",
      "Epoch 289/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0611 - acc: 0.9826 - val_loss: 7.6792 - val_acc: 0.1579\n",
      "Epoch 290/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0789 - acc: 0.9826 - val_loss: 7.7341 - val_acc: 0.1228\n",
      "Epoch 291/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1132 - acc: 0.9565 - val_loss: 7.1188 - val_acc: 0.1930\n",
      "Epoch 292/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0722 - acc: 0.9826 - val_loss: 6.4379 - val_acc: 0.2982\n",
      "Epoch 293/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0702 - acc: 0.9826 - val_loss: 7.8655 - val_acc: 0.1579\n",
      "Epoch 294/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0706 - acc: 0.9652 - val_loss: 7.4362 - val_acc: 0.1754\n",
      "Epoch 295/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0931 - acc: 0.9478 - val_loss: 7.0983 - val_acc: 0.1579\n",
      "Epoch 296/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0650 - acc: 0.9826 - val_loss: 7.9395 - val_acc: 0.1228\n",
      "Epoch 297/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0616 - acc: 0.9826 - val_loss: 7.0784 - val_acc: 0.2982\n",
      "Epoch 298/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0898 - acc: 0.9565 - val_loss: 8.3485 - val_acc: 0.1404\n",
      "Epoch 299/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0716 - acc: 0.9652 - val_loss: 7.1181 - val_acc: 0.2456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0787 - acc: 0.9652 - val_loss: 8.6089 - val_acc: 0.0526\n",
      "Epoch 301/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0648 - acc: 0.9826 - val_loss: 7.5662 - val_acc: 0.1930\n",
      "Epoch 302/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0813 - acc: 0.9739 - val_loss: 6.9490 - val_acc: 0.1930\n",
      "Epoch 303/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1027 - acc: 0.9565 - val_loss: 7.9506 - val_acc: 0.1228\n",
      "Epoch 304/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0791 - acc: 0.9652 - val_loss: 7.3745 - val_acc: 0.2456\n",
      "Epoch 305/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0747 - acc: 0.9739 - val_loss: 8.7892 - val_acc: 0.1053\n",
      "Epoch 306/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0824 - acc: 0.9565 - val_loss: 7.5136 - val_acc: 0.2456\n",
      "Epoch 307/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2432 - acc: 0.9217 - val_loss: 8.0837 - val_acc: 0.1754\n",
      "Epoch 308/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0704 - acc: 0.9826 - val_loss: 7.9520 - val_acc: 0.0877\n",
      "Epoch 309/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1049 - acc: 0.9565 - val_loss: 7.7090 - val_acc: 0.2105\n",
      "Epoch 310/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0555 - acc: 0.9913 - val_loss: 7.7430 - val_acc: 0.1579\n",
      "Epoch 311/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0801 - acc: 0.9652 - val_loss: 7.8500 - val_acc: 0.1930\n",
      "Epoch 312/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0684 - acc: 0.9826 - val_loss: 8.0778 - val_acc: 0.1404\n",
      "Epoch 313/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.1292 - acc: 0.9652 - val_loss: 8.1748 - val_acc: 0.1404\n",
      "Epoch 314/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1304 - acc: 0.9391 - val_loss: 8.2425 - val_acc: 0.1053\n",
      "Epoch 315/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0843 - acc: 0.9739 - val_loss: 7.7059 - val_acc: 0.1579\n",
      "Epoch 316/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0777 - acc: 0.9739 - val_loss: 8.5247 - val_acc: 0.1228\n",
      "Epoch 317/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0674 - acc: 0.9826 - val_loss: 7.8468 - val_acc: 0.1930\n",
      "Epoch 318/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0638 - acc: 0.9739 - val_loss: 7.2348 - val_acc: 0.2105\n",
      "Epoch 319/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0737 - acc: 0.9652 - val_loss: 7.8642 - val_acc: 0.1754\n",
      "Epoch 320/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0563 - acc: 0.9826 - val_loss: 8.4521 - val_acc: 0.1228\n",
      "Epoch 321/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0529 - acc: 0.9826 - val_loss: 7.5630 - val_acc: 0.2456\n",
      "Epoch 322/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0756 - acc: 0.9565 - val_loss: 8.6181 - val_acc: 0.0702\n",
      "Epoch 323/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1801 - acc: 0.9478 - val_loss: 6.9905 - val_acc: 0.1754\n",
      "Epoch 324/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0677 - acc: 0.9913 - val_loss: 7.1750 - val_acc: 0.1404\n",
      "Epoch 325/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1360 - acc: 0.9304 - val_loss: 7.2557 - val_acc: 0.2281\n",
      "Epoch 326/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0922 - acc: 0.9565 - val_loss: 7.7994 - val_acc: 0.1228\n",
      "Epoch 327/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0893 - acc: 0.9652 - val_loss: 6.4401 - val_acc: 0.2982\n",
      "Epoch 328/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0640 - acc: 0.9913 - val_loss: 6.9648 - val_acc: 0.2281\n",
      "Epoch 329/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1170 - acc: 0.9478 - val_loss: 7.2105 - val_acc: 0.1930\n",
      "Epoch 330/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0792 - acc: 0.9739 - val_loss: 6.8982 - val_acc: 0.2105\n",
      "Epoch 331/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0718 - acc: 0.9826 - val_loss: 7.5036 - val_acc: 0.1754\n",
      "Epoch 332/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0706 - acc: 0.9652 - val_loss: 8.3152 - val_acc: 0.1228\n",
      "Epoch 333/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0532 - acc: 0.9826 - val_loss: 8.3227 - val_acc: 0.1053\n",
      "Epoch 334/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0394 - acc: 0.9913 - val_loss: 8.6461 - val_acc: 0.0877\n",
      "Epoch 335/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0399 - acc: 0.9913 - val_loss: 8.8746 - val_acc: 0.1053\n",
      "Epoch 336/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0312 - acc: 1.0000 - val_loss: 8.7199 - val_acc: 0.1404\n",
      "Epoch 337/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0513 - acc: 0.9913 - val_loss: 6.5858 - val_acc: 0.3158\n",
      "Epoch 338/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1754 - acc: 0.9652 - val_loss: 8.0775 - val_acc: 0.2105\n",
      "Epoch 339/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0602 - acc: 0.9826 - val_loss: 8.8986 - val_acc: 0.1228\n",
      "Epoch 340/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0665 - acc: 0.9739 - val_loss: 7.6562 - val_acc: 0.2456\n",
      "Epoch 341/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.0983 - acc: 0.9478 - val_loss: 8.2067 - val_acc: 0.1930\n",
      "Epoch 342/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0602 - acc: 0.9913 - val_loss: 8.4475 - val_acc: 0.1579\n",
      "Epoch 343/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0484 - acc: 0.9913 - val_loss: 8.4616 - val_acc: 0.1579\n",
      "Epoch 344/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0428 - acc: 0.9913 - val_loss: 8.2321 - val_acc: 0.1579\n",
      "Epoch 345/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0400 - acc: 0.9913 - val_loss: 8.1415 - val_acc: 0.1579\n",
      "Epoch 346/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0484 - acc: 0.9913 - val_loss: 8.7005 - val_acc: 0.1228\n",
      "Epoch 347/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.0436 - acc: 0.9826 - val_loss: 8.8177 - val_acc: 0.1053\n",
      "Epoch 348/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0522 - acc: 0.9826 - val_loss: 7.9756 - val_acc: 0.2281\n",
      "Epoch 349/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0360 - acc: 0.9913 - val_loss: 8.7728 - val_acc: 0.1404\n",
      "Epoch 350/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0311 - acc: 0.9913 - val_loss: 8.4138 - val_acc: 0.1579\n",
      "Epoch 351/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0523 - acc: 0.9826 - val_loss: 8.4209 - val_acc: 0.1754\n",
      "Epoch 352/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0626 - acc: 0.9913 - val_loss: 8.1713 - val_acc: 0.2105\n",
      "Epoch 353/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1259 - acc: 0.9565 - val_loss: 7.6713 - val_acc: 0.2456\n",
      "Epoch 354/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0609 - acc: 0.9913 - val_loss: 8.0514 - val_acc: 0.2632\n",
      "Epoch 355/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0471 - acc: 1.0000 - val_loss: 7.9658 - val_acc: 0.2105\n",
      "Epoch 356/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0514 - acc: 0.9739 - val_loss: 9.4517 - val_acc: 0.0877\n",
      "Epoch 357/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0394 - acc: 0.9826 - val_loss: 8.1145 - val_acc: 0.2456\n",
      "Epoch 358/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0464 - acc: 0.9826 - val_loss: 8.0047 - val_acc: 0.2456\n",
      "Epoch 359/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0456 - acc: 1.0000 - val_loss: 8.5696 - val_acc: 0.1228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0514 - acc: 0.9739 - val_loss: 8.3052 - val_acc: 0.2105\n",
      "Epoch 361/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 8.6303 - val_acc: 0.1579\n",
      "Epoch 362/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0554 - acc: 0.9913 - val_loss: 7.8874 - val_acc: 0.1754\n",
      "Epoch 363/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0584 - acc: 0.9826 - val_loss: 8.6705 - val_acc: 0.1579\n",
      "Epoch 364/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0294 - acc: 1.0000 - val_loss: 8.1336 - val_acc: 0.1930\n",
      "Epoch 365/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2177 - acc: 0.9565 - val_loss: 7.0176 - val_acc: 0.1930\n",
      "Epoch 366/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1887 - acc: 0.9217 - val_loss: 7.5524 - val_acc: 0.2281\n",
      "Epoch 367/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0985 - acc: 0.9565 - val_loss: 7.9007 - val_acc: 0.1228\n",
      "Epoch 368/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0344 - acc: 1.0000 - val_loss: 8.5427 - val_acc: 0.1228\n",
      "Epoch 369/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0603 - acc: 0.9739 - val_loss: 8.4959 - val_acc: 0.0877\n",
      "Epoch 370/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0493 - acc: 0.9913 - val_loss: 9.3071 - val_acc: 0.0526\n",
      "Epoch 371/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0550 - acc: 0.9826 - val_loss: 7.9578 - val_acc: 0.1754\n",
      "Epoch 372/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 7.8234 - val_acc: 0.2281\n",
      "Epoch 373/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0840 - acc: 0.9652 - val_loss: 8.7858 - val_acc: 0.1053\n",
      "Epoch 374/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0570 - acc: 0.9826 - val_loss: 8.7445 - val_acc: 0.1579\n",
      "Epoch 375/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0441 - acc: 0.9913 - val_loss: 8.0281 - val_acc: 0.1754\n",
      "Epoch 376/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 8.1750 - val_acc: 0.1404\n",
      "Epoch 377/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0384 - acc: 0.9913 - val_loss: 8.2394 - val_acc: 0.1579\n",
      "Epoch 378/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0250 - acc: 1.0000 - val_loss: 8.0020 - val_acc: 0.1754\n",
      "Epoch 379/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0710 - acc: 0.9913 - val_loss: 8.9107 - val_acc: 0.1228\n",
      "Epoch 380/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 8.7039 - val_acc: 0.1579\n",
      "Epoch 381/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0484 - acc: 0.9826 - val_loss: 8.6808 - val_acc: 0.1930\n",
      "Epoch 382/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.1056 - acc: 0.9391 - val_loss: 9.3806 - val_acc: 0.0702\n",
      "Epoch 383/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0719 - acc: 0.9652 - val_loss: 7.6877 - val_acc: 0.3158\n",
      "Epoch 384/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2189 - acc: 0.9043 - val_loss: 8.7761 - val_acc: 0.1228\n",
      "Epoch 385/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0982 - acc: 0.9478 - val_loss: 7.5660 - val_acc: 0.2281\n",
      "Epoch 386/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0554 - acc: 0.9826 - val_loss: 8.1335 - val_acc: 0.1579\n",
      "Epoch 387/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0579 - acc: 0.9826 - val_loss: 8.8583 - val_acc: 0.1404\n",
      "Epoch 388/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0455 - acc: 0.9826 - val_loss: 8.6139 - val_acc: 0.1404\n",
      "Epoch 389/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0302 - acc: 0.9913 - val_loss: 8.1315 - val_acc: 0.2105\n",
      "Epoch 390/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0280 - acc: 1.0000 - val_loss: 8.4443 - val_acc: 0.1579\n",
      "Epoch 391/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0256 - acc: 0.9913 - val_loss: 7.6610 - val_acc: 0.2281\n",
      "Epoch 392/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0188 - acc: 1.0000 - val_loss: 7.7016 - val_acc: 0.2281\n",
      "Epoch 393/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0205 - acc: 1.0000 - val_loss: 8.0204 - val_acc: 0.1754\n",
      "Epoch 394/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 8.0266 - val_acc: 0.1930\n",
      "Epoch 395/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0331 - acc: 0.9913 - val_loss: 8.5791 - val_acc: 0.1053\n",
      "Epoch 396/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0283 - acc: 0.9913 - val_loss: 7.8789 - val_acc: 0.2281\n",
      "Epoch 397/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 8.3639 - val_acc: 0.1930\n",
      "Epoch 398/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0242 - acc: 0.9913 - val_loss: 7.7761 - val_acc: 0.2105\n",
      "Epoch 399/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 8.7316 - val_acc: 0.1228\n",
      "Epoch 400/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0195 - acc: 0.9913 - val_loss: 8.3957 - val_acc: 0.1579\n",
      "Epoch 401/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0411 - acc: 0.9739 - val_loss: 8.0840 - val_acc: 0.1930\n",
      "Epoch 402/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0287 - acc: 0.9913 - val_loss: 8.7220 - val_acc: 0.1579\n",
      "Epoch 403/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 8.1556 - val_acc: 0.1930\n",
      "Epoch 404/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0410 - acc: 0.9826 - val_loss: 9.1293 - val_acc: 0.1228\n",
      "Epoch 405/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0779 - acc: 0.9652 - val_loss: 8.5406 - val_acc: 0.1579\n",
      "Epoch 406/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0436 - acc: 0.9826 - val_loss: 8.5419 - val_acc: 0.1579\n",
      "Epoch 407/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 8.9654 - val_acc: 0.1404\n",
      "Epoch 408/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 9.0015 - val_acc: 0.1228\n",
      "Epoch 409/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0923 - acc: 0.9739 - val_loss: 8.6232 - val_acc: 0.1754\n",
      "Epoch 410/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1028 - acc: 0.9565 - val_loss: 8.8098 - val_acc: 0.1404\n",
      "Epoch 411/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0245 - acc: 0.9913 - val_loss: 9.4108 - val_acc: 0.1228\n",
      "Epoch 412/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0289 - acc: 0.9913 - val_loss: 9.4302 - val_acc: 0.1404\n",
      "Epoch 413/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0438 - acc: 0.9913 - val_loss: 7.9585 - val_acc: 0.1930\n",
      "Epoch 414/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0574 - acc: 0.9826 - val_loss: 7.7392 - val_acc: 0.1754\n",
      "Epoch 415/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0181 - acc: 1.0000 - val_loss: 8.6487 - val_acc: 0.1404\n",
      "Epoch 416/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 8.3731 - val_acc: 0.1754\n",
      "Epoch 417/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 9.2728 - val_acc: 0.1228\n",
      "Epoch 418/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 8.9327 - val_acc: 0.1579\n",
      "Epoch 419/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0302 - acc: 1.0000 - val_loss: 8.2269 - val_acc: 0.2105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0537 - acc: 0.9826 - val_loss: 9.1702 - val_acc: 0.1228\n",
      "Epoch 421/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0249 - acc: 0.9913 - val_loss: 8.8342 - val_acc: 0.1228\n",
      "Epoch 422/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0503 - acc: 0.9913 - val_loss: 8.8003 - val_acc: 0.1579\n",
      "Epoch 423/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0539 - acc: 0.9913 - val_loss: 9.1780 - val_acc: 0.1404\n",
      "Epoch 424/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 8.7515 - val_acc: 0.1754\n",
      "Epoch 425/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0246 - acc: 0.9913 - val_loss: 8.2639 - val_acc: 0.1930\n",
      "Epoch 426/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0414 - acc: 0.9826 - val_loss: 9.3681 - val_acc: 0.1053\n",
      "Epoch 427/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0450 - acc: 0.9826 - val_loss: 7.9583 - val_acc: 0.1930\n",
      "Epoch 428/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 8.4726 - val_acc: 0.1930\n",
      "Epoch 429/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0355 - acc: 0.9913 - val_loss: 9.9528 - val_acc: 0.0877\n",
      "Epoch 430/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0433 - acc: 0.9739 - val_loss: 7.9312 - val_acc: 0.2456\n",
      "Epoch 431/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0501 - acc: 0.9739 - val_loss: 9.1099 - val_acc: 0.1404\n",
      "Epoch 432/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0285 - acc: 0.9913 - val_loss: 8.4791 - val_acc: 0.1754\n",
      "Epoch 433/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 8.4059 - val_acc: 0.2105\n",
      "Epoch 434/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0445 - acc: 0.9739 - val_loss: 8.9127 - val_acc: 0.1228\n",
      "Epoch 435/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0336 - acc: 0.9826 - val_loss: 9.0084 - val_acc: 0.1404\n",
      "Epoch 436/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0264 - acc: 0.9913 - val_loss: 9.0987 - val_acc: 0.1579\n",
      "Epoch 437/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0344 - acc: 0.9913 - val_loss: 9.1539 - val_acc: 0.1228\n",
      "Epoch 438/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0222 - acc: 0.9913 - val_loss: 8.7685 - val_acc: 0.1930\n",
      "Epoch 439/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 8.4985 - val_acc: 0.2456\n",
      "Epoch 440/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 9.0023 - val_acc: 0.1754\n",
      "Epoch 441/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 8.8795 - val_acc: 0.1754\n",
      "Epoch 442/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 8.8757 - val_acc: 0.1579\n",
      "Epoch 443/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 8.9104 - val_acc: 0.1754\n",
      "Epoch 444/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 9.0808 - val_acc: 0.1930\n",
      "Epoch 445/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 10.7240 - val_acc: 0.0702\n",
      "Epoch 446/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0281 - acc: 0.9826 - val_loss: 9.4209 - val_acc: 0.1579\n",
      "Epoch 447/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 8.7332 - val_acc: 0.1930\n",
      "Epoch 448/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 9.5591 - val_acc: 0.1404\n",
      "Epoch 449/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0843 - acc: 0.9478 - val_loss: 8.8170 - val_acc: 0.1754\n",
      "Epoch 450/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0529 - acc: 0.9913 - val_loss: 8.6406 - val_acc: 0.1404\n",
      "Epoch 451/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0314 - acc: 0.9913 - val_loss: 8.5798 - val_acc: 0.2105\n",
      "Epoch 452/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0211 - acc: 1.0000 - val_loss: 8.9838 - val_acc: 0.1579\n",
      "Epoch 453/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1243 - acc: 0.9478 - val_loss: 8.9422 - val_acc: 0.1404\n",
      "Epoch 454/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0462 - acc: 0.9913 - val_loss: 8.1301 - val_acc: 0.2632\n",
      "Epoch 455/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0249 - acc: 0.9913 - val_loss: 8.2553 - val_acc: 0.2807\n",
      "Epoch 456/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0390 - acc: 0.9913 - val_loss: 8.8263 - val_acc: 0.1930\n",
      "Epoch 457/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0321 - acc: 0.9913 - val_loss: 8.5679 - val_acc: 0.2281\n",
      "Epoch 458/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 9.4066 - val_acc: 0.1404\n",
      "Epoch 459/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.0568 - acc: 0.9739 - val_loss: 10.3754 - val_acc: 0.0877\n",
      "Epoch 460/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0512 - acc: 0.9826 - val_loss: 8.0672 - val_acc: 0.2807\n",
      "Epoch 461/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0249 - acc: 1.0000 - val_loss: 8.9312 - val_acc: 0.1404\n",
      "Epoch 462/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0260 - acc: 0.9913 - val_loss: 8.8743 - val_acc: 0.1930\n",
      "Epoch 463/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0237 - acc: 0.9913 - val_loss: 9.1089 - val_acc: 0.1579\n",
      "Epoch 464/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 9.1266 - val_acc: 0.1930\n",
      "Epoch 465/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 8.8836 - val_acc: 0.1754\n",
      "Epoch 466/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 8.6675 - val_acc: 0.2632\n",
      "Epoch 467/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 9.1060 - val_acc: 0.1754\n",
      "Epoch 468/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0181 - acc: 1.0000 - val_loss: 9.9643 - val_acc: 0.1053\n",
      "Epoch 469/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 9.6542 - val_acc: 0.1579\n",
      "Epoch 470/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0132 - acc: 0.9913 - val_loss: 8.6701 - val_acc: 0.2456\n",
      "Epoch 471/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0257 - acc: 0.9913 - val_loss: 9.0205 - val_acc: 0.1754\n",
      "Epoch 472/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0183 - acc: 0.9913 - val_loss: 8.5012 - val_acc: 0.2105\n",
      "Epoch 473/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0322 - acc: 0.9826 - val_loss: 8.5911 - val_acc: 0.2105\n",
      "Epoch 474/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0408 - acc: 0.9739 - val_loss: 8.7789 - val_acc: 0.1930\n",
      "Epoch 475/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0594 - acc: 0.9652 - val_loss: 8.2901 - val_acc: 0.2105\n",
      "Epoch 476/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0390 - acc: 0.9913 - val_loss: 9.4382 - val_acc: 0.1404\n",
      "Epoch 477/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2895 - acc: 0.8870 - val_loss: 8.0462 - val_acc: 0.1930\n",
      "Epoch 478/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2699 - acc: 0.9478 - val_loss: 8.5347 - val_acc: 0.2105\n",
      "Epoch 479/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0453 - acc: 0.9913 - val_loss: 8.8620 - val_acc: 0.1930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0249 - acc: 1.0000 - val_loss: 8.4222 - val_acc: 0.2281\n",
      "Epoch 481/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0212 - acc: 0.9913 - val_loss: 8.2757 - val_acc: 0.2456\n",
      "Epoch 482/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 8.9703 - val_acc: 0.1579\n",
      "Epoch 483/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0372 - acc: 0.9826 - val_loss: 9.2190 - val_acc: 0.1228\n",
      "Epoch 484/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 9.1861 - val_acc: 0.1579\n",
      "Epoch 485/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0178 - acc: 0.9913 - val_loss: 8.8041 - val_acc: 0.1930\n",
      "Epoch 486/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 8.7177 - val_acc: 0.2281\n",
      "Epoch 487/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0190 - acc: 0.9913 - val_loss: 9.8281 - val_acc: 0.1228\n",
      "Epoch 488/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0943 - acc: 0.9652 - val_loss: 8.6390 - val_acc: 0.1930\n",
      "Epoch 489/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 8.3351 - val_acc: 0.2281\n",
      "Epoch 490/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0993 - acc: 0.9565 - val_loss: 8.3048 - val_acc: 0.2281\n",
      "Epoch 491/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 9.0430 - val_acc: 0.1579\n",
      "Epoch 492/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 9.1663 - val_acc: 0.1579\n",
      "Epoch 493/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 9.5224 - val_acc: 0.1579\n",
      "Epoch 494/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 9.6411 - val_acc: 0.1228\n",
      "Epoch 495/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 9.1849 - val_acc: 0.1404\n",
      "Epoch 496/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 9.4267 - val_acc: 0.1404\n",
      "Epoch 497/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 9.7418 - val_acc: 0.1053\n",
      "Epoch 498/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 9.7802 - val_acc: 0.1579\n",
      "Epoch 499/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0223 - acc: 1.0000 - val_loss: 9.1496 - val_acc: 0.1754\n",
      "Epoch 500/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 9.6252 - val_acc: 0.1404\n",
      "Epoch 501/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 8.9250 - val_acc: 0.2105\n",
      "Epoch 502/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0123 - acc: 0.9913 - val_loss: 8.1800 - val_acc: 0.3158\n",
      "Epoch 503/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 9.9588 - val_acc: 0.0877\n",
      "Epoch 504/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 9.2758 - val_acc: 0.1579\n",
      "Epoch 505/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 9.5985 - val_acc: 0.1404\n",
      "Epoch 506/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 9.3545 - val_acc: 0.1930\n",
      "Epoch 507/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0126 - acc: 0.9913 - val_loss: 8.6536 - val_acc: 0.2456\n",
      "Epoch 508/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0243 - acc: 1.0000 - val_loss: 9.3801 - val_acc: 0.1404\n",
      "Epoch 509/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2326 - acc: 0.9304 - val_loss: 8.3186 - val_acc: 0.1579\n",
      "Epoch 510/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0414 - acc: 0.9826 - val_loss: 8.8207 - val_acc: 0.1228\n",
      "Epoch 511/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0440 - acc: 0.9913 - val_loss: 8.3597 - val_acc: 0.1930\n",
      "Epoch 512/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0429 - acc: 0.9826 - val_loss: 7.7018 - val_acc: 0.2281\n",
      "Epoch 513/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1494 - acc: 0.9478 - val_loss: 8.4338 - val_acc: 0.1228\n",
      "Epoch 514/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0346 - acc: 0.9913 - val_loss: 7.8121 - val_acc: 0.1930\n",
      "Epoch 515/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0254 - acc: 0.9913 - val_loss: 8.4875 - val_acc: 0.2105\n",
      "Epoch 516/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0290 - acc: 0.9826 - val_loss: 8.2814 - val_acc: 0.1579\n",
      "Epoch 517/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 8.4697 - val_acc: 0.1754\n",
      "Epoch 518/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 8.6087 - val_acc: 0.1754\n",
      "Epoch 519/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 8.5384 - val_acc: 0.1930\n",
      "Epoch 520/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0264 - acc: 0.9826 - val_loss: 8.3670 - val_acc: 0.2105\n",
      "Epoch 521/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 8.3480 - val_acc: 0.1930\n",
      "Epoch 522/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 8.4320 - val_acc: 0.1930\n",
      "Epoch 523/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 8.5810 - val_acc: 0.1930\n",
      "Epoch 524/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 8.4807 - val_acc: 0.1930\n",
      "Epoch 525/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 8.6627 - val_acc: 0.1930\n",
      "Epoch 526/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0254 - acc: 0.9913 - val_loss: 8.9928 - val_acc: 0.1579\n",
      "Epoch 527/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0449 - acc: 0.9913 - val_loss: 8.2491 - val_acc: 0.1754\n",
      "Epoch 528/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 8.3785 - val_acc: 0.1930\n",
      "Epoch 529/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 9.2187 - val_acc: 0.2105\n",
      "Epoch 530/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0292 - acc: 0.9913 - val_loss: 8.8718 - val_acc: 0.1754\n",
      "Epoch 531/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0461 - acc: 0.9739 - val_loss: 8.8756 - val_acc: 0.1579\n",
      "Epoch 532/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0824 - acc: 0.9739 - val_loss: 8.8465 - val_acc: 0.1754\n",
      "Epoch 533/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1128 - acc: 0.9652 - val_loss: 9.7324 - val_acc: 0.0877\n",
      "Epoch 534/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0473 - acc: 0.9826 - val_loss: 7.6650 - val_acc: 0.2281\n",
      "Epoch 535/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 8.1799 - val_acc: 0.1930\n",
      "Epoch 536/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0181 - acc: 1.0000 - val_loss: 8.6612 - val_acc: 0.1754\n",
      "Epoch 537/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 8.8903 - val_acc: 0.1754\n",
      "Epoch 538/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0149 - acc: 0.9913 - val_loss: 7.9348 - val_acc: 0.1404\n",
      "Epoch 539/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0274 - acc: 1.0000 - val_loss: 8.8029 - val_acc: 0.1228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 9.4166 - val_acc: 0.1228\n",
      "Epoch 541/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0197 - acc: 0.9826 - val_loss: 7.9282 - val_acc: 0.2807\n",
      "Epoch 542/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 8.4231 - val_acc: 0.2456\n",
      "Epoch 543/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 9.3326 - val_acc: 0.1579\n",
      "Epoch 544/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0223 - acc: 0.9913 - val_loss: 9.2993 - val_acc: 0.1404\n",
      "Epoch 545/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 8.9905 - val_acc: 0.1930\n",
      "Epoch 546/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0311 - acc: 0.9913 - val_loss: 8.3749 - val_acc: 0.2281\n",
      "Epoch 547/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0299 - acc: 0.9913 - val_loss: 8.7054 - val_acc: 0.1754\n",
      "Epoch 548/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 8.9197 - val_acc: 0.1754\n",
      "Epoch 549/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 9.2384 - val_acc: 0.1579\n",
      "Epoch 550/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 9.1373 - val_acc: 0.1579\n",
      "Epoch 551/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 9.2768 - val_acc: 0.1754\n",
      "Epoch 552/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 8.8477 - val_acc: 0.1579\n",
      "Epoch 553/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0443 - acc: 0.9826 - val_loss: 8.8845 - val_acc: 0.1404\n",
      "Epoch 554/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 8.7659 - val_acc: 0.1930\n",
      "Epoch 555/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 9.2287 - val_acc: 0.1754\n",
      "Epoch 556/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 9.1896 - val_acc: 0.1754\n",
      "Epoch 557/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 8.8782 - val_acc: 0.1930\n",
      "Epoch 558/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 9.1253 - val_acc: 0.1579\n",
      "Epoch 559/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 9.0225 - val_acc: 0.1579\n",
      "Epoch 560/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0124 - acc: 0.9913 - val_loss: 9.1244 - val_acc: 0.2105\n",
      "Epoch 561/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0279 - acc: 0.9913 - val_loss: 9.9340 - val_acc: 0.1053\n",
      "Epoch 562/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1563 - acc: 0.9478 - val_loss: 7.8263 - val_acc: 0.1930\n",
      "Epoch 563/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0564 - acc: 0.9826 - val_loss: 9.4651 - val_acc: 0.1404\n",
      "Epoch 564/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0366 - acc: 0.9826 - val_loss: 10.2016 - val_acc: 0.1053\n",
      "Epoch 565/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0391 - acc: 0.9739 - val_loss: 8.4888 - val_acc: 0.1930\n",
      "Epoch 566/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0578 - acc: 0.9652 - val_loss: 9.8921 - val_acc: 0.1228\n",
      "Epoch 567/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.0494 - acc: 0.9739 - val_loss: 9.6430 - val_acc: 0.1053\n",
      "Epoch 568/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0360 - acc: 0.9739 - val_loss: 9.5342 - val_acc: 0.1228\n",
      "Epoch 569/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0164 - acc: 0.9913 - val_loss: 9.1158 - val_acc: 0.1404\n",
      "Epoch 570/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 9.7299 - val_acc: 0.1404\n",
      "Epoch 571/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 9.9554 - val_acc: 0.1404\n",
      "Epoch 572/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 9.8905 - val_acc: 0.1404\n",
      "Epoch 573/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0222 - acc: 0.9826 - val_loss: 9.3454 - val_acc: 0.1228\n",
      "Epoch 574/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 9.2379 - val_acc: 0.1579\n",
      "Epoch 575/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 9.2984 - val_acc: 0.2105\n",
      "Epoch 576/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 9.5789 - val_acc: 0.1404\n",
      "Epoch 577/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 9.6667 - val_acc: 0.1404\n",
      "Epoch 578/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1514 - acc: 0.9565 - val_loss: 7.8776 - val_acc: 0.1754\n",
      "Epoch 579/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2036 - acc: 0.9565 - val_loss: 8.3037 - val_acc: 0.1404\n",
      "Epoch 580/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0596 - acc: 0.9913 - val_loss: 8.3244 - val_acc: 0.1930\n",
      "Epoch 581/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0886 - acc: 0.9739 - val_loss: 6.7810 - val_acc: 0.3509\n",
      "Epoch 582/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0783 - acc: 0.9739 - val_loss: 8.1345 - val_acc: 0.2105\n",
      "Epoch 583/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 9.2694 - val_acc: 0.1579\n",
      "Epoch 584/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 9.0286 - val_acc: 0.1930\n",
      "Epoch 585/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 9.2556 - val_acc: 0.1579\n",
      "Epoch 586/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 9.3389 - val_acc: 0.1579\n",
      "Epoch 587/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 9.6974 - val_acc: 0.1754\n",
      "Epoch 588/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 9.7294 - val_acc: 0.1754\n",
      "Epoch 589/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 9.7303 - val_acc: 0.1754\n",
      "Epoch 590/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 9.4917 - val_acc: 0.1930\n",
      "Epoch 591/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 9.4929 - val_acc: 0.1754\n",
      "Epoch 592/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0153 - acc: 0.9913 - val_loss: 9.4755 - val_acc: 0.1228\n",
      "Epoch 593/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 10.1797 - val_acc: 0.1754\n",
      "Epoch 594/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0438 - acc: 0.9739 - val_loss: 8.1409 - val_acc: 0.2105\n",
      "Epoch 595/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 9.0431 - val_acc: 0.1930\n",
      "Epoch 596/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 8.9125 - val_acc: 0.1579\n",
      "Epoch 597/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 8.9874 - val_acc: 0.1754\n",
      "Epoch 598/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 9.4994 - val_acc: 0.1579\n",
      "Epoch 599/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 8.7370 - val_acc: 0.1930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 9.2020 - val_acc: 0.1930\n",
      "Epoch 601/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 9.6593 - val_acc: 0.1404\n",
      "Epoch 602/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 9.5875 - val_acc: 0.1579\n",
      "Epoch 603/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 9.6100 - val_acc: 0.1404\n",
      "Epoch 604/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 9.6571 - val_acc: 0.1404\n",
      "Epoch 605/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 9.2498 - val_acc: 0.1754\n",
      "Epoch 606/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 9.5122 - val_acc: 0.1579\n",
      "Epoch 607/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 9.2868 - val_acc: 0.1754\n",
      "Epoch 608/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 9.9145 - val_acc: 0.1228\n",
      "Epoch 609/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 9.6982 - val_acc: 0.1579\n",
      "Epoch 610/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 10.1228 - val_acc: 0.1754\n",
      "Epoch 611/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1362 - acc: 0.9565 - val_loss: 9.3617 - val_acc: 0.0877\n",
      "Epoch 612/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2773 - acc: 0.8957 - val_loss: 6.9955 - val_acc: 0.2281\n",
      "Epoch 613/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.3243 - acc: 0.9130 - val_loss: 8.0916 - val_acc: 0.1579\n",
      "Epoch 614/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2859 - acc: 0.9478 - val_loss: 7.6942 - val_acc: 0.1579\n",
      "Epoch 615/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1754 - acc: 0.9652 - val_loss: 9.6423 - val_acc: 0.0877\n",
      "Epoch 616/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0912 - acc: 0.9739 - val_loss: 8.7646 - val_acc: 0.1053\n",
      "Epoch 617/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2572 - acc: 0.9391 - val_loss: 7.9159 - val_acc: 0.1754\n",
      "Epoch 618/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0774 - acc: 0.9565 - val_loss: 6.9996 - val_acc: 0.2632\n",
      "Epoch 619/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0500 - acc: 0.9826 - val_loss: 7.7369 - val_acc: 0.1754\n",
      "Epoch 620/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0297 - acc: 1.0000 - val_loss: 8.2928 - val_acc: 0.1404\n",
      "Epoch 621/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0347 - acc: 0.9913 - val_loss: 7.5505 - val_acc: 0.2281\n",
      "Epoch 622/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 8.0146 - val_acc: 0.2281\n",
      "Epoch 623/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 8.4491 - val_acc: 0.1579\n",
      "Epoch 624/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0303 - acc: 0.9913 - val_loss: 8.0414 - val_acc: 0.1930\n",
      "Epoch 625/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0397 - acc: 0.9826 - val_loss: 8.9924 - val_acc: 0.1404\n",
      "Epoch 626/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0404 - acc: 0.9913 - val_loss: 7.6509 - val_acc: 0.2632\n",
      "Epoch 627/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0497 - acc: 0.9826 - val_loss: 8.0898 - val_acc: 0.1930\n",
      "Epoch 628/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0290 - acc: 0.9913 - val_loss: 8.6696 - val_acc: 0.1754\n",
      "Epoch 629/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0429 - acc: 0.9739 - val_loss: 7.3763 - val_acc: 0.2632\n",
      "Epoch 630/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 8.0271 - val_acc: 0.2807\n",
      "Epoch 631/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0549 - acc: 0.9739 - val_loss: 8.1479 - val_acc: 0.1930\n",
      "Epoch 632/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0280 - acc: 0.9913 - val_loss: 9.0422 - val_acc: 0.1754\n",
      "Epoch 633/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0605 - acc: 0.9652 - val_loss: 9.6641 - val_acc: 0.1228\n",
      "Epoch 634/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0452 - acc: 0.9826 - val_loss: 8.7720 - val_acc: 0.1754\n",
      "Epoch 635/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 8.8783 - val_acc: 0.1754\n",
      "Epoch 636/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 8.5219 - val_acc: 0.1754\n",
      "Epoch 637/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0170 - acc: 0.9913 - val_loss: 8.9319 - val_acc: 0.1930\n",
      "Epoch 638/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0690 - acc: 0.9913 - val_loss: 9.2150 - val_acc: 0.1579\n",
      "Epoch 639/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0402 - acc: 0.9913 - val_loss: 8.6931 - val_acc: 0.1930\n",
      "Epoch 640/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0218 - acc: 0.9913 - val_loss: 8.6182 - val_acc: 0.1930\n",
      "Epoch 641/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0269 - acc: 0.9913 - val_loss: 9.4891 - val_acc: 0.1754\n",
      "Epoch 642/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0584 - acc: 0.9739 - val_loss: 9.8335 - val_acc: 0.1404\n",
      "Epoch 643/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0719 - acc: 0.9739 - val_loss: 8.1806 - val_acc: 0.2456\n",
      "Epoch 644/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0409 - acc: 0.9826 - val_loss: 9.5882 - val_acc: 0.1404\n",
      "Epoch 645/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1080 - acc: 0.9652 - val_loss: 8.3841 - val_acc: 0.1754\n",
      "Epoch 646/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0265 - acc: 0.9913 - val_loss: 7.9635 - val_acc: 0.2281\n",
      "Epoch 647/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 8.8866 - val_acc: 0.1579\n",
      "Epoch 648/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 8.1329 - val_acc: 0.1930\n",
      "Epoch 649/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 8.1915 - val_acc: 0.1930\n",
      "Epoch 650/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0197 - acc: 0.9913 - val_loss: 8.9360 - val_acc: 0.1404\n",
      "Epoch 651/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0420 - acc: 0.9826 - val_loss: 8.1788 - val_acc: 0.1754\n",
      "Epoch 652/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 8.7186 - val_acc: 0.1579\n",
      "Epoch 653/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0257 - acc: 0.9913 - val_loss: 8.9114 - val_acc: 0.1930\n",
      "Epoch 654/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0629 - acc: 0.9826 - val_loss: 9.1049 - val_acc: 0.1053\n",
      "Epoch 655/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0545 - acc: 0.9739 - val_loss: 8.4885 - val_acc: 0.1404\n",
      "Epoch 656/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0425 - acc: 0.9739 - val_loss: 8.3452 - val_acc: 0.1930\n",
      "Epoch 657/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0251 - acc: 1.0000 - val_loss: 8.9075 - val_acc: 0.1754\n",
      "Epoch 658/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0262 - acc: 0.9913 - val_loss: 8.6178 - val_acc: 0.1754\n",
      "Epoch 659/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0204 - acc: 0.9913 - val_loss: 8.7398 - val_acc: 0.1579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0288 - acc: 0.9913 - val_loss: 8.3582 - val_acc: 0.1579\n",
      "Epoch 661/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 8.5881 - val_acc: 0.1754\n",
      "Epoch 662/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0180 - acc: 1.0000 - val_loss: 10.1896 - val_acc: 0.1228\n",
      "Epoch 663/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0790 - acc: 0.9652 - val_loss: 8.8190 - val_acc: 0.2105\n",
      "Epoch 664/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0260 - acc: 0.9913 - val_loss: 8.1462 - val_acc: 0.2281\n",
      "Epoch 665/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0768 - acc: 0.9826 - val_loss: 8.1268 - val_acc: 0.1754\n",
      "Epoch 666/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0315 - acc: 0.9913 - val_loss: 8.4700 - val_acc: 0.1579\n",
      "Epoch 667/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0295 - acc: 1.0000 - val_loss: 9.0784 - val_acc: 0.1930\n",
      "Epoch 668/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0173 - acc: 0.9913 - val_loss: 8.4012 - val_acc: 0.1930\n",
      "Epoch 669/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0201 - acc: 0.9913 - val_loss: 8.7975 - val_acc: 0.2105\n",
      "Epoch 670/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0493 - acc: 0.9913 - val_loss: 9.2796 - val_acc: 0.1754\n",
      "Epoch 671/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0377 - acc: 0.9739 - val_loss: 9.6553 - val_acc: 0.1404\n",
      "Epoch 672/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0643 - acc: 0.9652 - val_loss: 8.7620 - val_acc: 0.1754\n",
      "Epoch 673/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0279 - acc: 0.9826 - val_loss: 9.2741 - val_acc: 0.1404\n",
      "Epoch 674/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0254 - acc: 1.0000 - val_loss: 9.2940 - val_acc: 0.1754\n",
      "Epoch 675/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0233 - acc: 0.9913 - val_loss: 9.0005 - val_acc: 0.1754\n",
      "Epoch 676/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0350 - acc: 0.9913 - val_loss: 8.0218 - val_acc: 0.2632\n",
      "Epoch 677/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0261 - acc: 0.9913 - val_loss: 9.0392 - val_acc: 0.1579\n",
      "Epoch 678/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 8.4995 - val_acc: 0.1930\n",
      "Epoch 679/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0148 - acc: 1.0000 - val_loss: 8.9846 - val_acc: 0.1404\n",
      "Epoch 680/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 8.5016 - val_acc: 0.1754\n",
      "Epoch 681/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 8.9176 - val_acc: 0.1754\n",
      "Epoch 682/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 9.6113 - val_acc: 0.1579\n",
      "Epoch 683/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0307 - acc: 0.9826 - val_loss: 8.8985 - val_acc: 0.1579\n",
      "Epoch 684/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0309 - acc: 0.9913 - val_loss: 7.8129 - val_acc: 0.3158\n",
      "Epoch 685/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0504 - acc: 0.9652 - val_loss: 10.0911 - val_acc: 0.1053\n",
      "Epoch 686/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0649 - acc: 0.9739 - val_loss: 9.2514 - val_acc: 0.1754\n",
      "Epoch 687/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0420 - acc: 0.9826 - val_loss: 8.5145 - val_acc: 0.1930\n",
      "Epoch 688/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0296 - acc: 0.9913 - val_loss: 8.5362 - val_acc: 0.1930\n",
      "Epoch 689/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 8.7503 - val_acc: 0.1754\n",
      "Epoch 690/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 8.7137 - val_acc: 0.1754\n",
      "Epoch 691/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 9.4337 - val_acc: 0.1754\n",
      "Epoch 692/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 9.2945 - val_acc: 0.1754\n",
      "Epoch 693/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 9.5662 - val_acc: 0.1754\n",
      "Epoch 694/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0233 - acc: 0.9826 - val_loss: 8.7989 - val_acc: 0.2456\n",
      "Epoch 695/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0353 - acc: 0.9826 - val_loss: 10.4373 - val_acc: 0.1404\n",
      "Epoch 696/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0976 - acc: 0.9565 - val_loss: 8.6478 - val_acc: 0.1754\n",
      "Epoch 697/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1216 - acc: 0.9478 - val_loss: 8.7194 - val_acc: 0.1930\n",
      "Epoch 698/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 9.7267 - val_acc: 0.1228\n",
      "Epoch 699/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 9.0565 - val_acc: 0.1754\n",
      "Epoch 700/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0234 - acc: 1.0000 - val_loss: 9.1578 - val_acc: 0.1754\n",
      "Epoch 701/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0402 - acc: 0.9913 - val_loss: 10.5707 - val_acc: 0.0877\n",
      "Epoch 702/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1088 - acc: 0.9652 - val_loss: 9.2399 - val_acc: 0.1404\n",
      "Epoch 703/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0381 - acc: 0.9826 - val_loss: 8.8167 - val_acc: 0.1930\n",
      "Epoch 704/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 9.6652 - val_acc: 0.1404\n",
      "Epoch 705/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 9.8127 - val_acc: 0.1228\n",
      "Epoch 706/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0338 - acc: 0.9913 - val_loss: 9.1356 - val_acc: 0.1754\n",
      "Epoch 707/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0407 - acc: 0.9913 - val_loss: 9.5348 - val_acc: 0.1579\n",
      "Epoch 708/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0391 - acc: 0.9739 - val_loss: 9.0862 - val_acc: 0.2105\n",
      "Epoch 709/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0178 - acc: 0.9913 - val_loss: 8.9329 - val_acc: 0.2456\n",
      "Epoch 710/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0246 - acc: 0.9913 - val_loss: 8.9679 - val_acc: 0.1930\n",
      "Epoch 711/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0227 - acc: 0.9913 - val_loss: 9.3398 - val_acc: 0.1579\n",
      "Epoch 712/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 9.4375 - val_acc: 0.1404\n",
      "Epoch 713/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 9.4989 - val_acc: 0.1754\n",
      "Epoch 714/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 9.8373 - val_acc: 0.1404\n",
      "Epoch 715/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0514 - acc: 0.9826 - val_loss: 8.6810 - val_acc: 0.1754\n",
      "Epoch 716/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0383 - acc: 0.9826 - val_loss: 8.9840 - val_acc: 0.1754\n",
      "Epoch 717/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0304 - acc: 0.9913 - val_loss: 9.1822 - val_acc: 0.1754\n",
      "Epoch 718/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 9.6422 - val_acc: 0.1404\n",
      "Epoch 719/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 9.4721 - val_acc: 0.1754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 9.4142 - val_acc: 0.1754\n",
      "Epoch 721/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 9.7328 - val_acc: 0.1754\n",
      "Epoch 722/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 9.4090 - val_acc: 0.1754\n",
      "Epoch 723/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0165 - acc: 0.9913 - val_loss: 10.0564 - val_acc: 0.0877\n",
      "Epoch 724/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0342 - acc: 0.9913 - val_loss: 9.4729 - val_acc: 0.1754\n",
      "Epoch 725/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0132 - acc: 0.9913 - val_loss: 9.8262 - val_acc: 0.1404\n",
      "Epoch 726/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 10.1139 - val_acc: 0.1579\n",
      "Epoch 727/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0378 - acc: 0.9826 - val_loss: 10.3930 - val_acc: 0.0702\n",
      "Epoch 728/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.4200 - acc: 0.9217 - val_loss: 7.6569 - val_acc: 0.3509\n",
      "Epoch 729/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0851 - acc: 0.9826 - val_loss: 9.3223 - val_acc: 0.1579\n",
      "Epoch 730/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0304 - acc: 0.9913 - val_loss: 8.7708 - val_acc: 0.1754\n",
      "Epoch 731/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0451 - acc: 0.9826 - val_loss: 8.8666 - val_acc: 0.1754\n",
      "Epoch 732/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0409 - acc: 0.9826 - val_loss: 8.3945 - val_acc: 0.1754\n",
      "Epoch 733/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0277 - acc: 1.0000 - val_loss: 8.6882 - val_acc: 0.1404\n",
      "Epoch 734/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 8.5483 - val_acc: 0.1579\n",
      "Epoch 735/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0196 - acc: 1.0000 - val_loss: 8.8951 - val_acc: 0.1579\n",
      "Epoch 736/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0173 - acc: 0.9913 - val_loss: 8.8192 - val_acc: 0.1754\n",
      "Epoch 737/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0729 - acc: 0.9826 - val_loss: 9.4825 - val_acc: 0.1053\n",
      "Epoch 738/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1329 - acc: 0.9739 - val_loss: 8.6485 - val_acc: 0.1754\n",
      "Epoch 739/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0452 - acc: 0.9826 - val_loss: 8.8235 - val_acc: 0.2105\n",
      "Epoch 740/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0198 - acc: 0.9826 - val_loss: 9.8545 - val_acc: 0.1579\n",
      "Epoch 741/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 8.9493 - val_acc: 0.1930\n",
      "Epoch 742/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 9.1028 - val_acc: 0.1754\n",
      "Epoch 743/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 9.5761 - val_acc: 0.1754\n",
      "Epoch 744/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 9.2302 - val_acc: 0.1930\n",
      "Epoch 745/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 9.6097 - val_acc: 0.1754\n",
      "Epoch 746/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0245 - acc: 0.9826 - val_loss: 10.2222 - val_acc: 0.1754\n",
      "Epoch 747/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0679 - acc: 0.9739 - val_loss: 8.4748 - val_acc: 0.2105\n",
      "Epoch 748/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 9.6686 - val_acc: 0.1754\n",
      "Epoch 749/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0181 - acc: 0.9913 - val_loss: 9.9853 - val_acc: 0.1754\n",
      "Epoch 750/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 9.4841 - val_acc: 0.1754\n",
      "Epoch 751/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 9.2728 - val_acc: 0.1754\n",
      "Epoch 752/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0149 - acc: 0.9913 - val_loss: 8.9889 - val_acc: 0.1754\n",
      "Epoch 753/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0302 - acc: 0.9913 - val_loss: 9.5214 - val_acc: 0.1579\n",
      "Epoch 754/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 9.6085 - val_acc: 0.1579\n",
      "Epoch 755/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 9.5184 - val_acc: 0.1754\n",
      "Epoch 756/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 9.5422 - val_acc: 0.1754\n",
      "Epoch 757/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 9.6772 - val_acc: 0.1754\n",
      "Epoch 758/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 10.3922 - val_acc: 0.1754\n",
      "Epoch 759/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 9.7210 - val_acc: 0.1754\n",
      "Epoch 760/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0568 - acc: 0.9826 - val_loss: 10.0579 - val_acc: 0.1228\n",
      "Epoch 761/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1020 - acc: 0.9652 - val_loss: 9.9316 - val_acc: 0.1053\n",
      "Epoch 762/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0647 - acc: 0.9826 - val_loss: 9.9517 - val_acc: 0.1579\n",
      "Epoch 763/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0633 - acc: 0.9652 - val_loss: 8.8983 - val_acc: 0.2105\n",
      "Epoch 764/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 8.7873 - val_acc: 0.2105\n",
      "Epoch 765/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0242 - acc: 0.9913 - val_loss: 9.6548 - val_acc: 0.1579\n",
      "Epoch 766/1000\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 9.9582 - val_acc: 0.1579\n",
      "Epoch 767/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 9.7189 - val_acc: 0.1579\n",
      "Epoch 768/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 9.5345 - val_acc: 0.1754\n",
      "Epoch 769/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0935 - acc: 0.9652 - val_loss: 8.8716 - val_acc: 0.2105\n",
      "Epoch 770/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0325 - acc: 0.9826 - val_loss: 9.2809 - val_acc: 0.1754\n",
      "Epoch 771/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0254 - acc: 0.9913 - val_loss: 9.9251 - val_acc: 0.1228\n",
      "Epoch 772/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0134 - acc: 0.9913 - val_loss: 9.1765 - val_acc: 0.1404\n",
      "Epoch 773/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0261 - acc: 0.9913 - val_loss: 10.3488 - val_acc: 0.1053\n",
      "Epoch 774/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0724 - acc: 0.9739 - val_loss: 9.6069 - val_acc: 0.1930\n",
      "Epoch 775/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0533 - acc: 0.9913 - val_loss: 9.0959 - val_acc: 0.1754\n",
      "Epoch 776/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 9.9755 - val_acc: 0.1579\n",
      "Epoch 777/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0436 - acc: 0.9739 - val_loss: 10.6073 - val_acc: 0.1053\n",
      "Epoch 778/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0538 - acc: 0.9913 - val_loss: 9.0314 - val_acc: 0.1754\n",
      "Epoch 779/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0194 - acc: 0.9913 - val_loss: 9.0063 - val_acc: 0.1930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0274 - acc: 0.9913 - val_loss: 8.7670 - val_acc: 0.1930\n",
      "Epoch 781/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0495 - acc: 0.9739 - val_loss: 9.7236 - val_acc: 0.1579\n",
      "Epoch 782/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0305 - acc: 0.9913 - val_loss: 9.9056 - val_acc: 0.1404\n",
      "Epoch 783/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 9.7376 - val_acc: 0.1404\n",
      "Epoch 784/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0210 - acc: 0.9913 - val_loss: 9.6347 - val_acc: 0.1754\n",
      "Epoch 785/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0166 - acc: 0.9913 - val_loss: 9.0131 - val_acc: 0.1930\n",
      "Epoch 786/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 9.7265 - val_acc: 0.1404\n",
      "Epoch 787/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0142 - acc: 1.0000 - val_loss: 9.0739 - val_acc: 0.1754\n",
      "Epoch 788/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 10.0473 - val_acc: 0.1404\n",
      "Epoch 789/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 9.4461 - val_acc: 0.1754\n",
      "Epoch 790/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 10.0488 - val_acc: 0.1579\n",
      "Epoch 791/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 9.3812 - val_acc: 0.1754\n",
      "Epoch 792/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 9.3314 - val_acc: 0.1754\n",
      "Epoch 793/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 9.3788 - val_acc: 0.1754\n",
      "Epoch 794/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1083 - acc: 0.9652 - val_loss: 8.8524 - val_acc: 0.2281\n",
      "Epoch 795/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0184 - acc: 0.9913 - val_loss: 10.0973 - val_acc: 0.1228\n",
      "Epoch 796/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0283 - acc: 0.9913 - val_loss: 8.3759 - val_acc: 0.2982\n",
      "Epoch 797/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0199 - acc: 0.9826 - val_loss: 9.1066 - val_acc: 0.1754\n",
      "Epoch 798/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 10.1341 - val_acc: 0.1404\n",
      "Epoch 799/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0132 - acc: 0.9913 - val_loss: 8.9321 - val_acc: 0.1930\n",
      "Epoch 800/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 9.7232 - val_acc: 0.1754\n",
      "Epoch 801/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 10.2509 - val_acc: 0.1404\n",
      "Epoch 802/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0204 - acc: 0.9826 - val_loss: 8.6927 - val_acc: 0.2632\n",
      "Epoch 803/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0555 - acc: 0.9826 - val_loss: 7.9593 - val_acc: 0.3684\n",
      "Epoch 804/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0660 - acc: 0.9739 - val_loss: 8.9343 - val_acc: 0.2105\n",
      "Epoch 805/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0158 - acc: 0.9913 - val_loss: 9.1736 - val_acc: 0.1930\n",
      "Epoch 806/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0202 - acc: 0.9913 - val_loss: 8.9483 - val_acc: 0.1930\n",
      "Epoch 807/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0387 - acc: 0.9739 - val_loss: 8.7286 - val_acc: 0.1754\n",
      "Epoch 808/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 9.2774 - val_acc: 0.1404\n",
      "Epoch 809/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 9.3830 - val_acc: 0.1754\n",
      "Epoch 810/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 9.3562 - val_acc: 0.1754\n",
      "Epoch 811/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 9.5052 - val_acc: 0.1754\n",
      "Epoch 812/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0245 - acc: 0.982 - 1s 12ms/step - loss: 0.0237 - acc: 0.9826 - val_loss: 9.0611 - val_acc: 0.2281\n",
      "Epoch 813/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0457 - acc: 0.9739 - val_loss: 9.3158 - val_acc: 0.1579\n",
      "Epoch 814/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0374 - acc: 0.9739 - val_loss: 8.3117 - val_acc: 0.2982\n",
      "Epoch 815/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0141 - acc: 0.9913 - val_loss: 9.4906 - val_acc: 0.1579\n",
      "Epoch 816/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 9.2719 - val_acc: 0.1930\n",
      "Epoch 817/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 9.3988 - val_acc: 0.1754\n",
      "Epoch 818/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0176 - acc: 0.9913 - val_loss: 8.6512 - val_acc: 0.2281\n",
      "Epoch 819/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0389 - acc: 0.9739 - val_loss: 8.8438 - val_acc: 0.1754\n",
      "Epoch 820/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 9.7027 - val_acc: 0.1404\n",
      "Epoch 821/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 9.5829 - val_acc: 0.1754\n",
      "Epoch 822/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 9.4126 - val_acc: 0.1754\n",
      "Epoch 823/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 9.9044 - val_acc: 0.1754\n",
      "Epoch 824/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 9.9590 - val_acc: 0.1754\n",
      "Epoch 825/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 10.0030 - val_acc: 0.1754\n",
      "Epoch 826/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 9.6375 - val_acc: 0.1930\n",
      "Epoch 827/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 10.6709 - val_acc: 0.1404\n",
      "Epoch 828/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 9.6963 - val_acc: 0.1754\n",
      "Epoch 829/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 9.7022 - val_acc: 0.1754\n",
      "Epoch 830/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 9.9906 - val_acc: 0.1754\n",
      "Epoch 831/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0427 - acc: 0.9913 - val_loss: 9.8392 - val_acc: 0.1579\n",
      "Epoch 832/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0577 - acc: 0.9652 - val_loss: 9.0787 - val_acc: 0.1579\n",
      "Epoch 833/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 10.2036 - val_acc: 0.1404\n",
      "Epoch 834/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 9.7272 - val_acc: 0.1404\n",
      "Epoch 835/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0214 - acc: 0.9826 - val_loss: 8.7298 - val_acc: 0.2105\n",
      "Epoch 836/1000\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 0.1197 - acc: 0.9478 - val_loss: 8.9266 - val_acc: 0.2105\n",
      "Epoch 837/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0225 - acc: 0.9913 - val_loss: 10.4640 - val_acc: 0.1053\n",
      "Epoch 838/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0315 - acc: 0.9913 - val_loss: 9.3737 - val_acc: 0.1404\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0232 - acc: 0.9913 - val_loss: 9.5655 - val_acc: 0.1579\n",
      "Epoch 840/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 10.0611 - val_acc: 0.1579\n",
      "Epoch 841/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0577 - acc: 0.9913 - val_loss: 8.6394 - val_acc: 0.2105\n",
      "Epoch 842/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 9.3102 - val_acc: 0.1754\n",
      "Epoch 843/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 9.8036 - val_acc: 0.1404\n",
      "Epoch 844/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 9.2524 - val_acc: 0.1579\n",
      "Epoch 845/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 9.2575 - val_acc: 0.1754\n",
      "Epoch 846/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 9.9147 - val_acc: 0.1579\n",
      "Epoch 847/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 9.7427 - val_acc: 0.1579\n",
      "Epoch 848/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0438 - acc: 0.9826 - val_loss: 9.4863 - val_acc: 0.1930\n",
      "Epoch 849/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0158 - acc: 0.9913 - val_loss: 9.2332 - val_acc: 0.2105\n",
      "Epoch 850/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 9.4650 - val_acc: 0.1930\n",
      "Epoch 851/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 9.5658 - val_acc: 0.1754\n",
      "Epoch 852/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 10.0393 - val_acc: 0.1754\n",
      "Epoch 853/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 9.6918 - val_acc: 0.1754\n",
      "Epoch 854/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1712 - acc: 0.9391 - val_loss: 8.8925 - val_acc: 0.1754\n",
      "Epoch 855/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 9.4097 - val_acc: 0.1754\n",
      "Epoch 856/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0459 - acc: 0.9739 - val_loss: 9.5568 - val_acc: 0.1579\n",
      "Epoch 857/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0780 - acc: 0.9652 - val_loss: 8.9383 - val_acc: 0.1930\n",
      "Epoch 858/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0551 - acc: 0.9826 - val_loss: 8.8921 - val_acc: 0.1754\n",
      "Epoch 859/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 8.6212 - val_acc: 0.1754\n",
      "Epoch 860/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 8.7367 - val_acc: 0.1754\n",
      "Epoch 861/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 8.7648 - val_acc: 0.1754\n",
      "Epoch 862/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0189 - acc: 0.9913 - val_loss: 7.6436 - val_acc: 0.2456\n",
      "Epoch 863/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0760 - acc: 0.9739 - val_loss: 9.1037 - val_acc: 0.1930\n",
      "Epoch 864/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0720 - acc: 0.9652 - val_loss: 9.0743 - val_acc: 0.1754\n",
      "Epoch 865/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0231 - acc: 0.9826 - val_loss: 8.7246 - val_acc: 0.1930\n",
      "Epoch 866/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 9.1885 - val_acc: 0.1754\n",
      "Epoch 867/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 9.0723 - val_acc: 0.1754\n",
      "Epoch 868/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 9.6515 - val_acc: 0.1754\n",
      "Epoch 869/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 9.7721 - val_acc: 0.1754\n",
      "Epoch 870/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0121 - acc: 0.9913 - val_loss: 8.0919 - val_acc: 0.2807\n",
      "Epoch 871/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 9.2692 - val_acc: 0.1754\n",
      "Epoch 872/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 9.1561 - val_acc: 0.1754\n",
      "Epoch 873/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 9.3190 - val_acc: 0.1754\n",
      "Epoch 874/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 7.5880e-04 - acc: 1.0000 - val_loss: 9.4284 - val_acc: 0.1754\n",
      "Epoch 875/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 9.6259 - val_acc: 0.1754\n",
      "Epoch 876/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0171 - acc: 0.9913 - val_loss: 9.6875 - val_acc: 0.1579\n",
      "Epoch 877/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0175 - acc: 0.9913 - val_loss: 9.1666 - val_acc: 0.1579\n",
      "Epoch 878/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.000 - 1s 12ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 9.4882 - val_acc: 0.1579\n",
      "Epoch 879/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 9.3294 - val_acc: 0.1754\n",
      "Epoch 880/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 9.1892 - val_acc: 0.1754\n",
      "Epoch 881/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 10.3022 - val_acc: 0.1228\n",
      "Epoch 882/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0242 - acc: 0.9913 - val_loss: 9.9211 - val_acc: 0.1404\n",
      "Epoch 883/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 9.4285 - val_acc: 0.1754\n",
      "Epoch 884/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 9.3461 - val_acc: 0.1754\n",
      "Epoch 885/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 9.6869 - val_acc: 0.1754\n",
      "Epoch 886/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 9.4841 - val_acc: 0.1754\n",
      "Epoch 887/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 9.3208 - val_acc: 0.1930\n",
      "Epoch 888/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 9.6719 - val_acc: 0.1754\n",
      "Epoch 889/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 9.5427 - val_acc: 0.1754\n",
      "Epoch 890/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 9.5631 - val_acc: 0.1930\n",
      "Epoch 891/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 8.8494 - val_acc: 0.2456\n",
      "Epoch 892/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 9.7027 - val_acc: 0.1754\n",
      "Epoch 893/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 10.5225 - val_acc: 0.1404\n",
      "Epoch 894/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 9.7575 - val_acc: 0.1754\n",
      "Epoch 895/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 10.1316 - val_acc: 0.1579\n",
      "Epoch 896/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 9.9023 - val_acc: 0.1579\n",
      "Epoch 897/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 9.8656 - val_acc: 0.1579\n",
      "Epoch 898/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 9.3249 - val_acc: 0.2456\n",
      "Epoch 899/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1568 - acc: 0.9478 - val_loss: 9.7032 - val_acc: 0.1930\n",
      "Epoch 900/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0367 - acc: 0.9826 - val_loss: 8.2320 - val_acc: 0.2456\n",
      "Epoch 901/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 9.4081 - val_acc: 0.1930\n",
      "Epoch 902/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0486 - acc: 0.9913 - val_loss: 9.3864 - val_acc: 0.1579\n",
      "Epoch 903/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 9.5389 - val_acc: 0.1579\n",
      "Epoch 904/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 9.3639 - val_acc: 0.1579\n",
      "Epoch 905/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0156 - acc: 0.9913 - val_loss: 10.0107 - val_acc: 0.1579\n",
      "Epoch 906/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0409 - acc: 0.9826 - val_loss: 8.7965 - val_acc: 0.2281\n",
      "Epoch 907/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 10.1546 - val_acc: 0.1404\n",
      "Epoch 908/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0244 - acc: 0.9913 - val_loss: 12.1999 - val_acc: 0.1228\n",
      "Epoch 909/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0996 - acc: 0.9652 - val_loss: 9.0632 - val_acc: 0.2456\n",
      "Epoch 910/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0227 - acc: 0.9913 - val_loss: 9.1160 - val_acc: 0.2456\n",
      "Epoch 911/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0146 - acc: 0.9913 - val_loss: 8.6512 - val_acc: 0.2807\n",
      "Epoch 912/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 9.3425 - val_acc: 0.1754\n",
      "Epoch 913/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 9.5945 - val_acc: 0.1579\n",
      "Epoch 914/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 9.0196 - val_acc: 0.2456\n",
      "Epoch 915/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 9.8952 - val_acc: 0.1579\n",
      "Epoch 916/1000\n",
      "115/115 [==============================] - 2s 14ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 9.6994 - val_acc: 0.1579\n",
      "Epoch 917/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 9.4192 - val_acc: 0.1930\n",
      "Epoch 918/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 10.1006 - val_acc: 0.1404\n",
      "Epoch 919/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0244 - acc: 0.9913 - val_loss: 9.4214 - val_acc: 0.1579\n",
      "Epoch 920/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0179 - acc: 0.9913 - val_loss: 9.4679 - val_acc: 0.1579\n",
      "Epoch 921/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 9.8927 - val_acc: 0.1579\n",
      "Epoch 922/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 10.2039 - val_acc: 0.1579\n",
      "Epoch 923/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 9.9349 - val_acc: 0.1754\n",
      "Epoch 924/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0112 - acc: 0.9913 - val_loss: 9.6439 - val_acc: 0.1754\n",
      "Epoch 925/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 9.9806 - val_acc: 0.1404\n",
      "Epoch 926/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 10.5754 - val_acc: 0.1228\n",
      "Epoch 927/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 10.3776 - val_acc: 0.1404\n",
      "Epoch 928/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0159 - acc: 0.9913 - val_loss: 10.0028 - val_acc: 0.1930\n",
      "Epoch 929/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0242 - acc: 0.9913 - val_loss: 9.6667 - val_acc: 0.1930\n",
      "Epoch 930/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 9.8512 - val_acc: 0.1930\n",
      "Epoch 931/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 9.7487 - val_acc: 0.1579\n",
      "Epoch 932/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0154 - acc: 0.9913 - val_loss: 8.6002 - val_acc: 0.2982\n",
      "Epoch 933/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 8.4477 - val_acc: 0.2281\n",
      "Epoch 934/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1371 - acc: 0.9826 - val_loss: 10.3657 - val_acc: 0.1754\n",
      "Epoch 935/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1531 - acc: 0.9565 - val_loss: 8.6342 - val_acc: 0.2982\n",
      "Epoch 936/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.2533 - acc: 0.9391 - val_loss: 8.9016 - val_acc: 0.1754\n",
      "Epoch 937/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 8.8202 - val_acc: 0.1754\n",
      "Epoch 938/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 8.9802 - val_acc: 0.1930\n",
      "Epoch 939/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 9.1325 - val_acc: 0.1930\n",
      "Epoch 940/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 9.2882 - val_acc: 0.1930\n",
      "Epoch 941/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0181 - acc: 0.9913 - val_loss: 9.2284 - val_acc: 0.1930\n",
      "Epoch 942/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 8.8914 - val_acc: 0.2281\n",
      "Epoch 943/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 9.3474 - val_acc: 0.1930\n",
      "Epoch 944/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 9.2530 - val_acc: 0.1930\n",
      "Epoch 945/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 9.3525 - val_acc: 0.1930\n",
      "Epoch 946/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 9.6977 - val_acc: 0.1930\n",
      "Epoch 947/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 9.3804 - val_acc: 0.1930\n",
      "Epoch 948/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 9.1531 - val_acc: 0.2281\n",
      "Epoch 949/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 9.7389 - val_acc: 0.1930\n",
      "Epoch 950/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0163 - acc: 0.9913 - val_loss: 9.2250 - val_acc: 0.1930\n",
      "Epoch 951/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 9.4728 - val_acc: 0.1930\n",
      "Epoch 952/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0110 - acc: 0.9913 - val_loss: 8.9729 - val_acc: 0.2632\n",
      "Epoch 953/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0542 - acc: 0.9652 - val_loss: 9.8250 - val_acc: 0.1579\n",
      "Epoch 954/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0335 - acc: 0.9826 - val_loss: 9.2347 - val_acc: 0.2105\n",
      "Epoch 955/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 9.5315 - val_acc: 0.2105\n",
      "Epoch 956/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 9.4488 - val_acc: 0.1930\n",
      "Epoch 957/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0238 - acc: 0.9913 - val_loss: 8.3384 - val_acc: 0.3158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 958/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0162 - acc: 0.9913 - val_loss: 8.3744 - val_acc: 0.2807\n",
      "Epoch 959/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 10.1123 - val_acc: 0.1228\n",
      "Epoch 960/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 9.2090 - val_acc: 0.1579\n",
      "Epoch 961/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 8.8691 - val_acc: 0.2105\n",
      "Epoch 962/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 8.8153 - val_acc: 0.2456\n",
      "Epoch 963/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0484 - acc: 0.9913 - val_loss: 9.4127 - val_acc: 0.1930\n",
      "Epoch 964/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0424 - acc: 0.9739 - val_loss: 9.6293 - val_acc: 0.1579\n",
      "Epoch 965/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 9.7364 - val_acc: 0.1579\n",
      "Epoch 966/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0216 - acc: 0.9826 - val_loss: 9.9714 - val_acc: 0.1579\n",
      "Epoch 967/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0255 - acc: 0.9826 - val_loss: 8.2522 - val_acc: 0.3333\n",
      "Epoch 968/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.1264 - acc: 0.9826 - val_loss: 10.6440 - val_acc: 0.1053\n",
      "Epoch 969/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0502 - acc: 0.9826 - val_loss: 8.7683 - val_acc: 0.2105\n",
      "Epoch 970/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 8.8901 - val_acc: 0.2105\n",
      "Epoch 971/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 9.2131 - val_acc: 0.1579\n",
      "Epoch 972/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 9.3650 - val_acc: 0.1579\n",
      "Epoch 973/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 9.4458 - val_acc: 0.1579\n",
      "Epoch 974/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 9.0545e-04 - acc: 1.0000 - val_loss: 9.4667 - val_acc: 0.1579\n",
      "Epoch 975/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 9.5653 - val_acc: 0.1579\n",
      "Epoch 976/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 9.5840 - val_acc: 0.1579\n",
      "Epoch 977/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 6.1453e-04 - acc: 1.0000 - val_loss: 9.6479 - val_acc: 0.1579\n",
      "Epoch 978/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 8.5583 - val_acc: 0.2632\n",
      "Epoch 979/1000\n",
      "115/115 [==============================] - ETA: 0s - loss: 0.0081 - acc: 1.000 - 1s 12ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 9.1015 - val_acc: 0.1930\n",
      "Epoch 980/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 9.4164 - val_acc: 0.1579\n",
      "Epoch 981/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 9.3096 - val_acc: 0.1930\n",
      "Epoch 982/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 9.5501 - val_acc: 0.1754\n",
      "Epoch 983/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 9.5145 - val_acc: 0.1754\n",
      "Epoch 984/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 6.8560e-04 - acc: 1.0000 - val_loss: 9.6834 - val_acc: 0.1754\n",
      "Epoch 985/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 8.3446e-04 - acc: 1.0000 - val_loss: 9.7546 - val_acc: 0.1754\n",
      "Epoch 986/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 9.3255 - val_acc: 0.1930\n",
      "Epoch 987/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 9.9034 - val_acc: 0.1404\n",
      "Epoch 988/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 10.0691 - val_acc: 0.1228\n",
      "Epoch 989/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0281 - acc: 0.9913 - val_loss: 9.1517 - val_acc: 0.2105\n",
      "Epoch 990/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0670 - acc: 0.9826 - val_loss: 10.1708 - val_acc: 0.1053\n",
      "Epoch 991/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0840 - acc: 0.9739 - val_loss: 8.8935 - val_acc: 0.2456\n",
      "Epoch 992/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0240 - acc: 0.9826 - val_loss: 8.9877 - val_acc: 0.1579\n",
      "Epoch 993/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 9.2199 - val_acc: 0.1579\n",
      "Epoch 994/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 9.2794 - val_acc: 0.1404\n",
      "Epoch 995/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0358 - acc: 0.9826 - val_loss: 9.7948 - val_acc: 0.1404\n",
      "Epoch 996/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0510 - acc: 0.9826 - val_loss: 8.4208 - val_acc: 0.2807\n",
      "Epoch 997/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 9.3316 - val_acc: 0.1754\n",
      "Epoch 998/1000\n",
      "115/115 [==============================] - 2s 13ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 9.6283 - val_acc: 0.1754\n",
      "Epoch 999/1000\n",
      "115/115 [==============================] - 1s 13ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 9.1939 - val_acc: 0.1930\n",
      "Epoch 1000/1000\n",
      "115/115 [==============================] - 1s 12ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 9.5822 - val_acc: 0.1579\n"
     ]
    }
   ],
   "source": [
    "#STEP1. 定義訓練並進行訓練 \n",
    "# 定義訓練方式  \n",
    "#print(len(HRVdata),len(labelOneHot))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "  \n",
    "# 開始訓練  \n",
    "train_history = model.fit(x=HRVdata,  \n",
    "                          y=labelOneHot, validation_split=0.33,  \n",
    "                          epochs=1000, batch_size=1, verbose=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os  \n",
    "  \n",
    "def isDisplayAvl():  \n",
    "    return 'DISPLAY' in os.environ.keys()  \n",
    "  \n",
    "import matplotlib.pyplot as plt  \n",
    "def plot_image(image):  \n",
    "    fig = plt.gcf()  \n",
    "    fig.set_size_inches(2,2)  \n",
    "    plt.imshow(image, cmap='binary')  \n",
    "    plt.show()  \n",
    "  \n",
    "def plot_images_labels_predict(images, labels, prediction, idx, num=10):  \n",
    "    fig = plt.gcf()  \n",
    "    fig.set_size_inches(12, 14)  \n",
    "    if num > 25: num = 25  \n",
    "    for i in range(0, num):  \n",
    "        ax=plt.subplot(5,5, 1+i)  \n",
    "        ax.imshow(images[idx], cmap='binary')  \n",
    "        title = \"l=\" + str(labels[idx])  \n",
    "        if len(prediction) > 0:  \n",
    "            title = \"l={},p={}\".format(str(labels[idx]), str(prediction[idx]))  \n",
    "        else:  \n",
    "            title = \"l={}\".format(str(labels[idx]))  \n",
    "        ax.set_title(title, fontsize=10)  \n",
    "        ax.set_xticks([]); ax.set_yticks([])  \n",
    "        idx+=1  \n",
    "    plt.show()  \n",
    "  \n",
    "def show_train_history(train_history, train, validation):  \n",
    "    plt.plot(train_history.history[train])  \n",
    "    plt.plot(train_history.history[validation])  \n",
    "    plt.title('Train History')  \n",
    "    plt.ylabel(train)  \n",
    "    plt.xlabel('Epoch')  \n",
    "    plt.legend(['train', 'validation'], loc='upper left')  \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndbbX82Sck/0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1afc30134a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUZQ05/8D1fFXS6CUeEcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1afc316df60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from utils import *  \n",
    "#if isDisplayAvl():  \n",
    "show_train_history(train_history, 'acc', 'val_acc')  \n",
    "show_train_history(train_history, 'loss', 'val_loss') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 304us/step\n",
      "\n",
      "\t[Info] Accuracy of testing data = 89.5%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(HRVdata, labelOneHot)  \n",
    "print()  \n",
    "print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Info] Making prediction of X_Test4D_norm\n",
      "\n",
      "\t[Info] Show 172 prediction result (From 1):\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0\n",
      " 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t[Info] Making prediction of X_Test4D_norm\")  \n",
    "prediction = model.predict_classes(HRVdata)  # Making prediction and save result to prediction  \n",
    "print()  \n",
    "print(\"\\t[Info] Show 172 prediction result (From 1):\")  \n",
    "print(\"%s\\n\" % (prediction[0:172])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#存設計好之model-------------------------------\n",
    "\n",
    "model.save('my_model_new.h5')   # HDF5 file, you have to pip3 install h5py if don't have it\n",
    "del model  # deletes the existing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 443us/step\n",
      "\n",
      "\t[Info] Accuracy of testing data after load = 81.4%\n",
      "\t[Info] Making prediction of X_Test4D_norm\n",
      "\n",
      "\t[Info] Show 172 prediction result (From 1):\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#讀進存好之model並測試是否test出來結果一樣\n",
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5')\n",
    "scores = model.evaluate(HRVdata, labelOneHot)  \n",
    "print()  \n",
    "print(\"\\t[Info] Accuracy of testing data after load = {:2.1f}%\".format(scores[1]*100.0)) \n",
    "\n",
    "print(\"\\t[Info] Making prediction of X_Test4D_norm\")  \n",
    "prediction = model.predict_classes(HRVdata)  # Making prediction and save result to prediction  \n",
    "print()  \n",
    "print(\"\\t[Info] Show 172 prediction result (From 1):\")  \n",
    "print(\"%s\\n\" % (prediction[0:172])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
